{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on Hand Written Digit Recognition\n",
    "\n",
    "In this tutorial we will go through the basic use case of MXNet and also touch on some advanced usages. This example is based on the MNIST dataset, which contains 70,000 images of hand written characters with 28-by-28 pixel size.\n",
    "\n",
    "This tutorial covers the following topics:\n",
    "- network definition.\n",
    "- Variable naming.\n",
    "- Basic data loading and training with feed-forward deep neural networks.\n",
    "- Monitoring intermediate outputs for debuging.\n",
    "- Custom training loop for advanced models.\n",
    "\n",
    "Letâ€™s train a 3-layer multilayer perceptron on the MNIST dataset to classify handwritten digits. \n",
    "\n",
    "First, let's load mxnet scala jar in classpath."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Scala kernel\n",
    "Add mxnet scala jar which is created as a part of MXNet Scala package installation in classpath as follows:\n",
    "\n",
    "**Note**: Process to add this jar in your scala kernel classpath can differ according to the scala kernel you are using.\n",
    "\n",
    "We have used [jupyter-scala kernel](https://github.com/alexarchambault/jupyter-scala) for creating this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "classpath.addPath(<path_to_jar>)\n",
    "\n",
    "e.g\n",
    "classpath.addPath(\"mxnet-full_2.11-osx-x86_64-cpu-0.1.2-SNAPSHOT.jar\")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mml.dmlc.mxnet._\u001b[0m\n",
       "\u001b[32mimport \u001b[36mml.dmlc.mxnet.optimizer.SGD\u001b[0m\n",
       "\u001b[32mimport \u001b[36mscala.collection.mutable.ListBuffer\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ml.dmlc.mxnet._\n",
    "import ml.dmlc.mxnet.optimizer.SGD\n",
    "import scala.collection.mutable.ListBuffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Definition\n",
    "\n",
    "Now, we can start constructing our network:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log4j:WARN No appenders could be found for logger (MXNetJVM).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@2aec6c99\n",
       "\u001b[36mfc1\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@60bcbe48\n",
       "\u001b[36mact1\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@60abab94\n",
       "\u001b[36mfc2\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@2665643d\n",
       "\u001b[36mact2\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@20b63589\n",
       "\u001b[36mfc3\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@25fd8129\n",
       "\u001b[36mmlp\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@18b77909"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// # Variables are place holders for input arrays. We give each variable a unique name.\n",
    "val data = Symbol.Variable(\"data\")\n",
    "\n",
    "// The input is fed to a fully connected layer that computes Y=WX+b.\n",
    "// This is the main computation module in the network.\n",
    "// Each layer also needs an unique name. We'll talk more about naming in the next section.\n",
    "val fc1 = Symbol.FullyConnected(name = \"fc1\")()(Map(\"data\" -> data, \"num_hidden\" -> 128))\n",
    "\n",
    "// Activation layers apply a non-linear function on the previous layer's output.\n",
    "// Here we use Rectified Linear Unit (ReLU) that computes Y = max(X, 0).\n",
    "val act1 = Symbol.Activation(name = \"relu1\")()(Map(\"data\" -> fc1, \"act_type\" -> \"relu\"))\n",
    "\n",
    "val fc2 = Symbol.FullyConnected(name = \"fc2\")()(Map(\"data\" -> act1, \"num_hidden\" -> 64))\n",
    "val act2 = Symbol.Activation(name = \"relu2\")()(Map(\"data\" -> fc2, \"act_type\" -> \"relu\"))\n",
    "val fc3 = Symbol.FullyConnected(name = \"fc3\")()(Map(\"data\" -> act2, \"num_hidden\" -> 10))\n",
    "\n",
    "// Finally we have a loss layer that compares the network's output with label and generates gradient signals.\n",
    "val mlp = Symbol.SoftmaxOutput(name = \"softmax\")()(Map(\"data\" -> fc3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Naming\n",
    "MXNet requires variable names to follow certain conventions:\n",
    "- All input arrays have a name. This includes inputs (data & label) and model parameters (weight, bias, etc).\n",
    "- Arrays can be renamed by creating named variable. Otherwise, a default name is given as 'SymbolName_ArrayName'. For example, FullyConnected symbol fc1's weight array is named as 'fc1_weight'.\n",
    "- Although you can also rename weight arrays with variables, weight array's name should always end with '_weight' and bias array '_bias'. MXNet relies on the suffixes of array names to correctly initialize & update them.\n",
    "Call listArguments method on a symbol to get the names of all its inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres3\u001b[0m: \u001b[32mIndexedSeq\u001b[0m[\u001b[32mString\u001b[0m] = \u001b[33mArrayBuffer\u001b[0m(\n",
       "  \u001b[32m\"data\"\u001b[0m,\n",
       "  \u001b[32m\"fc1_weight\"\u001b[0m,\n",
       "  \u001b[32m\"fc1_bias\"\u001b[0m,\n",
       "  \u001b[32m\"fc2_weight\"\u001b[0m,\n",
       "  \u001b[32m\"fc2_bias\"\u001b[0m,\n",
       "  \u001b[32m\"fc3_weight\"\u001b[0m,\n",
       "  \u001b[32m\"fc3_bias\"\u001b[0m,\n",
       "  \u001b[32m\"softmax_label\"\u001b[0m\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp.listArguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "We download the MNIST data using the [get_mnist_data script](https://github.com/dmlc/mxnet/blob/master/scala-package/core/scripts/get_mnist_data.sh). Now we can create data iterators from our MNIST data. A data iterator returns a batch of data examples each time for the network to process. MXNet provide a suite of basic DataIters for parsing different data format. \n",
    "\n",
    "Here we use MNISTIter, which wraps around a numpy array and each time slice a chunk from it along the first dimension. \n",
    "Change path of input files according to your system.\n",
    "Load the training and validation data using DataIterators as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainDataIter\u001b[0m: \u001b[32mDataIter\u001b[0m = non-empty iterator\n",
       "\u001b[36mvalDataIter\u001b[0m: \u001b[32mDataIter\u001b[0m = non-empty iterator"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// load MNIST dataset\n",
    "val trainDataIter = IO.MNISTIter(Map(\n",
    "  \"image\" -> \"data/train-images-idx3-ubyte\",\n",
    "  \"label\" -> \"data/train-labels-idx1-ubyte\",\n",
    "  \"data_shape\" -> \"(1, 28, 28)\",\n",
    "  \"label_name\" -> \"softmax_label\",\n",
    "  \"batch_size\" -> \"50\",\n",
    "  \"shuffle\" -> \"1\",\n",
    "  \"flat\" -> \"0\",\n",
    "  \"silent\" -> \"0\",\n",
    "  \"seed\" -> \"10\"))\n",
    "\n",
    "val valDataIter = IO.MNISTIter(Map(\n",
    "  \"image\" -> \"data/t10k-images-idx3-ubyte\",\n",
    "  \"label\" -> \"data/t10k-labels-idx1-ubyte\",\n",
    "  \"data_shape\" -> \"(1, 28, 28)\",\n",
    "  \"label_name\" -> \"softmax_label\",\n",
    "  \"batch_size\" -> \"50\",\n",
    "  \"shuffle\" -> \"1\",\n",
    "  \"flat\" -> \"0\", \"silent\" -> \"0\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "With the network and data source defined, we can finally start to train our model. We do this with MXNet's convenience wrapper for FeedForward builder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmodel\u001b[0m: \u001b[32mFeedForward\u001b[0m = ml.dmlc.mxnet.FeedForward@3d40f3b0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// setup model and fit the training data\n",
    "val model = FeedForward.newBuilder(mlp) // Use the network we just defined\n",
    "      .setContext(Context.cpu()) // Run on CPU \n",
    "      .setNumEpoch(10) // Train for 10 epochs\n",
    "      .setOptimizer(new SGD(learningRate = 0.1f, momentum = 0.9f, wd = 0.0001f)) // Learning rate, \n",
    "//Momentum and Weight decay for regularization\n",
    "      .setTrainData(trainDataIter) // Training data set\n",
    "      .setEvalData(valDataIter) // Testing data set. MXNet computes scores on test set every epoch\n",
    "      .build()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EvaluationÂ¶\n",
    "\n",
    "After the model is trained, we can evaluate it on a held out validation dataset and compare the predicted labels with the real labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mprobArrays\u001b[0m: \u001b[32mArray\u001b[0m[\u001b[32mNDArray\u001b[0m] = \u001b[33mArray\u001b[0m(ml.dmlc.mxnet.NDArray@7d18083e)\n",
       "\u001b[36mprob\u001b[0m: \u001b[32mNDArray\u001b[0m = ml.dmlc.mxnet.NDArray@426c4e40\n",
       "\u001b[36mlabels\u001b[0m: \u001b[32mListBuffer\u001b[0m[\u001b[32mNDArray\u001b[0m] = \u001b[33mListBuffer\u001b[0m(\n",
       "  ml.dmlc.mxnet.NDArray@2accfeb0,\n",
       "  ml.dmlc.mxnet.NDArray@5f74e322,\n",
       "  ml.dmlc.mxnet.NDArray@63792053,\n",
       "  ml.dmlc.mxnet.NDArray@3ed497c6,\n",
       "  ml.dmlc.mxnet.NDArray@51274f83,\n",
       "  ml.dmlc.mxnet.NDArray@4a0bed53,\n",
       "  ml.dmlc.mxnet.NDArray@476a7696,\n",
       "  ml.dmlc.mxnet.NDArray@3370c62e,\n",
       "  ml.dmlc.mxnet.NDArray@32e012b4,\n",
       "  ml.dmlc.mxnet.NDArray@d1db10e,\n",
       "  ml.dmlc.mxnet.NDArray@2b949b3e,\n",
       "  ml.dmlc.mxnet.NDArray@43f2a5f5,\n",
       "  ml.dmlc.mxnet.NDArray@27a485dd,\n",
       "  ml.dmlc.mxnet.NDArray@21c6cebf,\n",
       "  ml.dmlc.mxnet.NDArray@30d3eb9f,\n",
       "  ml.dmlc.mxnet.NDArray@1932251f,\n",
       "  ml.dmlc.mxnet.NDArray@47b7adba,\n",
       "  ml.dmlc.mxnet.NDArray@22e85214,\n",
       "  ml.dmlc.mxnet.NDArray@1f29cb21,\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36my\u001b[0m: \u001b[32mNDArray\u001b[0m = ml.dmlc.mxnet.NDArray@76d55afb\n",
       "\u001b[36mpredictedY\u001b[0m: \u001b[32mNDArrayFuncReturn\u001b[0m = ml.dmlc.mxnet.NDArrayFuncReturn@4786ef4d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val probArrays = model.predict(valDataIter)\n",
    "// in this case, we do not have multiple outputs\n",
    "require(probArrays.length == 1)\n",
    "val prob = probArrays(0)\n",
    "\n",
    "// get real labels\n",
    "valDataIter.reset()\n",
    "val labels = ListBuffer.empty[NDArray]\n",
    "while (valDataIter.hasNext) {\n",
    "  val evalData = valDataIter.next()\n",
    "  labels += evalData.label(0).copy()\n",
    "}\n",
    "val y = NDArray.concatenate(labels)\n",
    "\n",
    "// get predicted labels\n",
    "val predictedY = NDArray.argmax_channel(prob)\n",
    "require(y.shape == predictedY.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate the model's accuracy on the entire test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 0.9609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mnumCorrect\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m9609\u001b[0m\n",
       "\u001b[36mnumTotal\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m10000\u001b[0m\n",
       "\u001b[36macc\u001b[0m: \u001b[32mFloat\u001b[0m = \u001b[32m0.9609F\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// calculate accuracy\n",
    "var numCorrect = 0\n",
    "var numTotal = 0\n",
    "for ((labelElem, predElem) <- y.toArray zip predictedY.toArray) {\n",
    "  if (labelElem == predElem) {\n",
    "    numCorrect += 1\n",
    "  }\n",
    "  numTotal += 1\n",
    "}\n",
    "val acc = numCorrect.toFloat / numTotal\n",
    "println(s\"Final accuracy = $acc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next StepsÂ¶\n",
    "Check out more MXNet Scala resources below.\n",
    "\n",
    "[Scala API](http://mxnet.io/api/scala/)\n",
    "\n",
    "[More Scala Examples](https://github.com/dmlc/mxnet/tree/master/scala-package/examples/src/main/scala/ml/dmlc/mxnet/examples)\n",
    "\n",
    "[MXNet tutorials index](http://mxnet.io/tutorials/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
