{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "This tutorial we focus on how to feed the data into a training and inference program. Most training and inference modules in MXNet accepts data iterators, especially when reading large datasets from filesystems. MXNet uses an iterator to provide data to the neural network. Iterators do some preprocessing and generate batches for the neural network.\n",
    "\n",
    "MXNet provides basic iterators for MNIST and RecordIO images. To hide the cost of I/O, MXNet uses a prefetch strategy that enables parallelism for the learning process and data fetching. Data is automatically fetched by an independent thread. Here we discuss the API conventions and several provided iterators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Scala kernel\n",
    "Add mxnet scala jar which is created as a part of MXNet Scala package installation in classpath as follows:\n",
    "\n",
    "**Note**: Process to add this jar in your scala kernel classpath can differ according to the scala kernel you are using.\n",
    "\n",
    "We have used [jupyter-scala kernel](https://github.com/alexarchambault/jupyter-scala) for creating this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "classpath.addPath(<path_to_jar>)\n",
    "\n",
    "e.g\n",
    "classpath.addPath(\"mxnet-full_2.11-osx-x86_64-cpu-0.1.2-SNAPSHOT.jar\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Iterator\n",
    "\n",
    "MXNet's data iterator returns a batch of data in each `next` call. We first introduce what a data batch looks like and then how to write a basic data iterator.\n",
    "\n",
    "### Data Batch\n",
    "A data batch often contains n examples and the according labels. Here n is often called as the batch size.\n",
    "The following codes defines a valid data batch is able to be read by most training/inference modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mml.dmlc.mxnet._\u001b[0m\n",
       "\u001b[32mimport \u001b[36mscala.collection.immutable.ListMap\u001b[0m\n",
       "defined \u001b[32mclass \u001b[36mDataBatch\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ml.dmlc.mxnet._\n",
    "import scala.collection.immutable.ListMap\n",
    "\n",
    "class DataBatch(val data: IndexedSeq[NDArray],\n",
    "                val label: IndexedSeq[NDArray],\n",
    "                val index: IndexedSeq[Long],\n",
    "                val pad: Int,\n",
    "                // the key for the bucket that should be used for this batch,\n",
    "                // for bucketing io only\n",
    "                val bucketKey: AnyRef = null,\n",
    "                // use ListMap to indicate the order of data/label loading\n",
    "                // (must match the order of input data/label)\n",
    "                private val providedData: ListMap[String, Shape] = null,\n",
    "                private val providedLabel: ListMap[String, Shape] = null) {\n",
    "  /**\n",
    "   * Dispose its data and labels\n",
    "   * The object shall never be used after it is disposed.\n",
    "   */\n",
    "  def dispose(): Unit = {\n",
    "    if (data != null) {\n",
    "      data.foreach(arr => if (arr != null) arr.dispose())\n",
    "    }\n",
    "    if (label != null) {\n",
    "      label.foreach(arr => if (arr != null) arr.dispose())\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // The name and shape of data\n",
    "  def provideData: ListMap[String, Shape] = providedData\n",
    "\n",
    "  // The name and shape of label\n",
    "  def provideLabel: ListMap[String, Shape] = providedLabel\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explain what each attribute means:\n",
    "- **data** is a list of NDArray, each of them has $n$ length first dimension. For example, if an example is an image with size $224 \\times 224$ and RGB channels, then the array shape should be (n, 3, 224, 244). Note that the image batch format used by MXNet is\n",
    "\n",
    "$$\\textrm{batch_size} \\times \\textrm{num_channel} \\times \\textrm{height} \\times \\textrm{width}$$ \n",
    "\n",
    "The channels are often in RGB order.\n",
    "\n",
    "Each array will be copied into a free variable of the Symbol later. The mapping from arrays to free variables should be given by the provide_data attribute of the iterator, which will be discussed shortly.\n",
    "- **label** is also a list of NDArray. Often each NDArray is a 1-dimensional array with shape (n,). For classification, each class is represented by an integer starting from 0.\n",
    "- **pad** is an integer shows how many examples are for merely used for padding, which should be ignored in the results. A nonzero padding is often used when we reach the end of the data and the total number of examples cannot be divided by the batch size.\n",
    "- **providedData** is a ListMap of name and shape of the data.\n",
    "- **providedLabel** is a ListMap of name and shape of the label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Symbol and Data Variables\n",
    "Before moving the iterator, we first look at how to find which variables in a Symbol are for input data. In MXNet, an operator (mx.sym.*) has one or more input variables and output variables; some operators may have additional auxiliary variables for internal states. For an input variable of an operator, if do not assign it with an output of another operator during creating this operator, then this input variable is free. We need to assign it with external data before running.\n",
    "\n",
    "The following codes define a simple multilayer perceptron (MLP) and then print all free variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log4j:WARN No appenders could be found for logger (MXNetJVM).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mnumClasses\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m10\u001b[0m\n",
       "\u001b[36mdata\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@30a65ea0\n",
       "\u001b[36mfc1\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@200fe851\n",
       "\u001b[36mact1\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@28fd3448\n",
       "\u001b[36mfc2\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@671608bf\n",
       "\u001b[36mmlp\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@65c719a3\n",
       "\u001b[36mres2_6\u001b[0m: \u001b[32mIndexedSeq\u001b[0m[\u001b[32mString\u001b[0m] = \u001b[33mArrayBuffer\u001b[0m(\n",
       "  \u001b[32m\"data\"\u001b[0m,\n",
       "  \u001b[32m\"fc1_weight\"\u001b[0m,\n",
       "  \u001b[32m\"fc1_bias\"\u001b[0m,\n",
       "  \u001b[32m\"fc2_weight\"\u001b[0m,\n",
       "  \u001b[32m\"fc2_bias\"\u001b[0m,\n",
       "  \u001b[32m\"softmax_label\"\u001b[0m\n",
       ")\n",
       "\u001b[36mres2_7\u001b[0m: \u001b[32mIndexedSeq\u001b[0m[\u001b[32mString\u001b[0m] = \u001b[33mArrayBuffer\u001b[0m(\u001b[32m\"softmax_output\"\u001b[0m)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val numClasses = 10\n",
    "\n",
    "val data = Symbol.Variable(\"data\")\n",
    "val fc1 = Symbol.FullyConnected(name = \"fc1\")()(Map(\"data\" -> data, \"num_hidden\" -> 64))\n",
    "val act1 = Symbol.Activation(name = \"relu1\")()(Map(\"data\" -> fc1, \"act_type\" -> \"relu\"))\n",
    "val fc2 = Symbol.FullyConnected(name = \"fc2\")()(Map(\"data\" -> act1, \"num_hidden\" -> numClasses))\n",
    "val mlp = Symbol.SoftmaxOutput(name = \"softmax\")()(Map(\"data\" -> fc2))\n",
    "\n",
    "mlp.listArguments()\n",
    "mlp.listOutputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, we name a variable either by its operator's name if it is atomic (e.g. Symbol.Variable(\"data\")) or by the opname_varname convention. The varname often means what this variable is for:\n",
    "\n",
    "- weight : the weight parameters\n",
    "- bias : the bias parameters\n",
    "- output : the output\n",
    "- label : input label\n",
    "\n",
    "On the above example, now we know that there are 4 variables for parameters, and two for input data: data for examples and softmax_label for the according labels.\n",
    "\n",
    "The following example define a matrix factorization object function with rank 10 for recommendation systems. It has three input variables, user for user IDs, item for item IDs, and score is the rating user gives to item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mnumUsers\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m1000\u001b[0m\n",
       "\u001b[36mnumItems\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m1000\u001b[0m\n",
       "\u001b[36mk\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m10\u001b[0m\n",
       "\u001b[36muser\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@50a64721\n",
       "\u001b[36mitem\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@6f09fabd\n",
       "\u001b[36mscore\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@6cdc9943\n",
       "\u001b[36muser1\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@2971e218\n",
       "\u001b[36mitem1\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@4b0c2758\n",
       "\u001b[36mpred0\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@6bf0e096\n",
       "\u001b[36mpred1\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@636e7a2a\n",
       "\u001b[36mpred2\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@4529257d\n",
       "\u001b[36mpred\u001b[0m: \u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@6f35ec67"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val numUsers = 1000\n",
    "val numItems = 1000\n",
    "val k = 10 \n",
    "\n",
    "// input\n",
    "val user = Symbol.Variable(\"user\")\n",
    "val item = Symbol.Variable(\"item\")\n",
    "val score = Symbol.Variable(\"score\")\n",
    "\n",
    "// user feature lookup\n",
    "val user1 = Symbol.Embedding()()(Map(\"data\" -> user, \"input_dim\" -> numUsers, \"output_dim\" -> k))\n",
    "\n",
    "// item feature lookup\n",
    "val item1 = Symbol.Embedding()()(Map(\"data\" -> item, \"input_dim\" -> numItems, \"output_dim\" -> k))\n",
    "\n",
    "// predict by the inner product, which is elementwise product and then sum\n",
    "val pred0 = user1 * item1\n",
    "val pred1 = Symbol.sum_axis()()(Map(\"data\" -> pred0, \"axis\" -> 1))\n",
    "val pred2 = Symbol.Flatten()()(Map(\"data\" -> pred1))\n",
    "\n",
    "// loss layer\n",
    "val pred = Symbol.LinearRegressionOutput()()(Map(\"data\" -> pred2, \"label\" -> score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Iterators\n",
    "Now we are ready to show how to create a valid MXNet data iterator. An iterator should extend DataIter class and override following methods:\n",
    "\n",
    "- **reset()** method to restart reading from the beginning\n",
    "- **provideData()** to return a Listmap of (str, tuple) pairs, each pair stores an input data variable name and its shape. \n",
    "- **provideLabel()** method to return a Listmap of (str, tuple) pairs, which provides information about input labels.\n",
    "- **getData()** and **getLabel()** methods for getting data and label of current batch.\n",
    "- **getPad()** for getting the number of padding examples.\n",
    "- **getIndex()** for getting the index of current batch.\n",
    "- **next()** method to return a data batch.\n",
    "\n",
    "The following codes define a simple iterator that return some random data each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction \u001b[36mdataGen\u001b[0m\n",
       "defined \u001b[32mfunction \u001b[36mlabelGen\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    def dataGen(dim: Array[Int]) : Array[Array[Float]] ={\n",
    "        val r = new scala.util.Random(100)\n",
    "        Array.fill(dim(0), dim(1)) { 2*r.nextFloat-1 }\n",
    "    }\n",
    "    \n",
    "    def labelGen(lowLimit: Int, highLimit: Int, dim: Int) : Array[Float] ={\n",
    "        val r = new scala.util.Random(100)\n",
    "        val label = for (i <- lowLimit+1 to dim) yield r.nextInt(highLimit).asInstanceOf[Float]\n",
    "        label.toArray\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mscala.collection.mutable.ArrayBuffer\u001b[0m\n",
       "\u001b[36mnumBatches\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m10\u001b[0m\n",
       "defined \u001b[32mclass \u001b[36mSimpleIter\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scala.collection.mutable.ArrayBuffer\n",
    "val numBatches: Int=10\n",
    "\n",
    "class SimpleIter(dataNames: String, dataShapes: Shape, dataGen: Array[Array[Float]],\n",
    "                 labelNames: String, labelShapes: Shape, labelGen: Array[Float]) extends DataIter{\n",
    "\n",
    "    val _provideData = ListMap(dataNames -> dataShapes)\n",
    "    val _provideLabel = ListMap(labelNames -> labelShapes)\n",
    "    var curBatch = 0\n",
    "\n",
    "  // Get next data batch from iterator\n",
    "  override def next(): DataBatch = {\n",
    "    if (!hasNext) throw new NoSuchElementException\n",
    "\n",
    "      val data = Array(NDArray.array(dataGen.flatten.toArray, shape = dataShapes))\n",
    "      val label = Array(NDArray.array(labelGen, shape = labelShapes))\n",
    "      curBatch += 1\n",
    "          \n",
    "      new DataBatch(data=data,label=label, index=getIndex(), pad=getPad(), providedData=_provideData, providedLabel=_provideLabel)\n",
    "  }    \n",
    "    \n",
    "  // reset the iterator    \n",
    "  override def reset(): Unit = {\n",
    "    curBatch = 0\n",
    "  }\n",
    "  // Check for next batch\n",
    "  override def hasNext: Boolean = {\n",
    "      curBatch < numBatches\n",
    "  }\n",
    "    \n",
    "  override def batchSize: Int = numBatches\n",
    "  // Get data of current batch\n",
    "  override def getData(): IndexedSeq[NDArray] = IndexedSeq()\n",
    "  // Get the index of current batch\n",
    "  override def getIndex(): IndexedSeq[Long] = IndexedSeq[Long]()\n",
    "  // Get label of current batch\n",
    "  override def getLabel(): IndexedSeq[NDArray] = IndexedSeq()\n",
    "  // Get the number of padding examples in current batch\n",
    "  override def getPad(): Int = 0\n",
    "  // The name and shape of data provided by this iterator\n",
    "  override def provideData: ListMap[String, Shape] = _provideData\n",
    "  // The name and shape of label provided by this iterator\n",
    "  override def provideLabel: ListMap[String, Shape] = _provideLabel\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can feed the data iterator into a training problem. Here we used the Module class, more details about this class is discussed in module.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mml.dmlc.mxnet.module.{FitParams, Module}\u001b[0m\n",
       "\u001b[36mn\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m32\u001b[0m\n",
       "\u001b[36mdata\u001b[0m: \u001b[32mSimpleIter\u001b[0m = non-empty iterator\n",
       "\u001b[36mmod\u001b[0m: \u001b[32mmodule\u001b[0m.\u001b[32mModule\u001b[0m = ml.dmlc.mxnet.module.Module@4f52fe71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ml.dmlc.mxnet.module.{FitParams, Module}\n",
    "\n",
    "val n = 32\n",
    "val data = new SimpleIter(\"data\", Shape(n,100), \n",
    "                  dataGen(Array(n,100)),\n",
    "                  \"softmax_label\", Shape(n), \n",
    "                  labelGen(0, numClasses, n))\n",
    "\n",
    "val mod = new Module(mlp)\n",
    "mod.fit(data, numEpoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "While for Symbol pred, we need to provide three inputs, two for examples and one for label. Refer to the MatrixFactorization tutorial to know more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Iterators\n",
    "MXNet provides multiple efficient data iterators as follows:\n",
    "\n",
    "### MNISTIter\n",
    "MNISTIter is the easy way to iterate on the MNIST dataset. \n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- \"image\" and \"label\" - Dataset Param:  MNist Image and Label datapath\n",
    "- \"batch_size\" (int, optional, default='128') – Batch Param: Batch Size.\n",
    "- \"shuffle\" - Augmentation Param: Whether to shuffle data.\n",
    "- \"flat\" (boolean, optional, default=False) – Augmentation Param: Whether to flat the data into 1D.\n",
    "- \"seed\" (int, optional, default='0') – Augmentation Param: Random Seed.\n",
    "- \"silent\" (boolean, optional, default=False) – Auxiliary Param: Whether to print out data info.\n",
    "- \"num_parts (int, optional, default='1') – partition the data into multiple parts\n",
    "- \"part_index\" (int, optional, default='0') – the index of the part will read\n",
    "- \"prefetch_buffer\" (long (non-negative), optional, default=4) – Maximal Number of batches to prefetch\n",
    "- \"dtype\" ({None, 'float16', 'float32', 'float64', 'int32', 'uint8'},optional, default='None') – Output data type. None means no change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mparams\u001b[0m: \u001b[32mMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mString\u001b[0m] = \u001b[33mMap\u001b[0m(\n",
       "  \u001b[32m\"silent\"\u001b[0m -> \u001b[32m\"0\"\u001b[0m,\n",
       "  \u001b[32m\"seed\"\u001b[0m -> \u001b[32m\"10\"\u001b[0m,\n",
       "  \u001b[32m\"flat\"\u001b[0m -> \u001b[32m\"1\"\u001b[0m,\n",
       "  \u001b[32m\"image\"\u001b[0m -> \u001b[32m\"data/train-images-idx3-ubyte\"\u001b[0m,\n",
       "  \u001b[32m\"label\"\u001b[0m -> \u001b[32m\"data/train-labels-idx1-ubyte\"\u001b[0m,\n",
       "  \u001b[32m\"shuffle\"\u001b[0m -> \u001b[32m\"1\"\u001b[0m,\n",
       "  \u001b[32m\"data_shape\"\u001b[0m -> \u001b[32m\"(784,)\"\u001b[0m,\n",
       "  \u001b[32m\"batch_size\"\u001b[0m -> \u001b[32m\"100\"\u001b[0m\n",
       ")\n",
       "\u001b[36mmnistPack\u001b[0m: \u001b[32mDataPack\u001b[0m = \u001b[33mMXDataPack\u001b[0m(\n",
       "  ml.dmlc.mxnet.DataBatch@1c83152e,\n",
       "  ml.dmlc.mxnet.DataBatch@18820148,\n",
       "  ml.dmlc.mxnet.DataBatch@1410a0a5,\n",
       "  ml.dmlc.mxnet.DataBatch@45dfe674,\n",
       "  ml.dmlc.mxnet.DataBatch@4171b184,\n",
       "  ml.dmlc.mxnet.DataBatch@497170a3,\n",
       "  ml.dmlc.mxnet.DataBatch@58f5f4a0,\n",
       "  ml.dmlc.mxnet.DataBatch@6223558c,\n",
       "  ml.dmlc.mxnet.DataBatch@2e1235dd,\n",
       "  ml.dmlc.mxnet.DataBatch@6ca4bcd4,\n",
       "  ml.dmlc.mxnet.DataBatch@1b030514,\n",
       "  ml.dmlc.mxnet.DataBatch@63f4bccd,\n",
       "  ml.dmlc.mxnet.DataBatch@5c77d1b3,\n",
       "  ml.dmlc.mxnet.DataBatch@15fc84f5,\n",
       "  ml.dmlc.mxnet.DataBatch@16d418fb,\n",
       "  ml.dmlc.mxnet.DataBatch@5000cc38,\n",
       "  ml.dmlc.mxnet.DataBatch@321875c2,\n",
       "  ml.dmlc.mxnet.DataBatch@43b29458,\n",
       "  ml.dmlc.mxnet.DataBatch@75975f15,\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36mnBatch\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m600\u001b[0m\n",
       "\u001b[36mbatchCount\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m600\u001b[0m\n",
       "\u001b[36mmnistIter\u001b[0m: \u001b[32mDataIter\u001b[0m = non-empty iterator\n",
       "\u001b[36mprovideData\u001b[0m: \u001b[32mListMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mShape\u001b[0m] = \u001b[33mMap\u001b[0m(\u001b[32m\"data\"\u001b[0m -> (100,784))\n",
       "\u001b[36mprovideLabel\u001b[0m: \u001b[32mListMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mShape\u001b[0m] = \u001b[33mMap\u001b[0m(\u001b[32m\"label\"\u001b[0m -> (100))\n",
       "\u001b[36mres8_12\u001b[0m: \u001b[32mDataBatch\u001b[0m = ml.dmlc.mxnet.DataBatch@4e9f4579\n",
       "\u001b[36mlabel0\u001b[0m: \u001b[32mArray\u001b[0m[\u001b[32mFloat\u001b[0m] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[32m3.0F\u001b[0m,\n",
       "  \u001b[32m4.0F\u001b[0m,\n",
       "  \u001b[32m9.0F\u001b[0m,\n",
       "  \u001b[32m8.0F\u001b[0m,\n",
       "  \u001b[32m2.0F\u001b[0m,\n",
       "  \u001b[32m8.0F\u001b[0m,\n",
       "  \u001b[32m1.0F\u001b[0m,\n",
       "  \u001b[32m9.0F\u001b[0m,\n",
       "  \u001b[32m8.0F\u001b[0m,\n",
       "  \u001b[32m4.0F\u001b[0m,\n",
       "  \u001b[32m6.0F\u001b[0m,\n",
       "  \u001b[32m8.0F\u001b[0m,\n",
       "  \u001b[32m3.0F\u001b[0m,\n",
       "  \u001b[32m6.0F\u001b[0m,\n",
       "  \u001b[32m3.0F\u001b[0m,\n",
       "  \u001b[32m1.0F\u001b[0m,\n",
       "  \u001b[32m9.0F\u001b[0m,\n",
       "  \u001b[32m8.0F\u001b[0m,\n",
       "  \u001b[32m3.0F\u001b[0m,\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36mdata0\u001b[0m: \u001b[32mArray\u001b[0m[\u001b[32mFloat\u001b[0m] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36mres8_15\u001b[0m: \u001b[32mDataBatch\u001b[0m = ml.dmlc.mxnet.DataBatch@55a394de\n",
       "\u001b[36mres8_16\u001b[0m: \u001b[32mDataBatch\u001b[0m = ml.dmlc.mxnet.DataBatch@6123a79e\n",
       "\u001b[36mres8_17\u001b[0m: \u001b[32mDataBatch\u001b[0m = ml.dmlc.mxnet.DataBatch@639de812\n",
       "\u001b[36mres8_19\u001b[0m: \u001b[32mDataBatch\u001b[0m = ml.dmlc.mxnet.DataBatch@b0fdedf\n",
       "\u001b[36mlabel1\u001b[0m: \u001b[32mArray\u001b[0m[\u001b[32mFloat\u001b[0m] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[32m3.0F\u001b[0m,\n",
       "  \u001b[32m4.0F\u001b[0m,\n",
       "  \u001b[32m9.0F\u001b[0m,\n",
       "  \u001b[32m8.0F\u001b[0m,\n",
       "  \u001b[32m2.0F\u001b[0m,\n",
       "  \u001b[32m8.0F\u001b[0m,\n",
       "  \u001b[32m1.0F\u001b[0m,\n",
       "  \u001b[32m9.0F\u001b[0m,\n",
       "  \u001b[32m8.0F\u001b[0m,\n",
       "  \u001b[32m4.0F\u001b[0m,\n",
       "  \u001b[32m6.0F\u001b[0m,\n",
       "  \u001b[32m8.0F\u001b[0m,\n",
       "  \u001b[32m3.0F\u001b[0m,\n",
       "  \u001b[32m6.0F\u001b[0m,\n",
       "  \u001b[32m3.0F\u001b[0m,\n",
       "  \u001b[32m1.0F\u001b[0m,\n",
       "  \u001b[32m9.0F\u001b[0m,\n",
       "  \u001b[32m8.0F\u001b[0m,\n",
       "  \u001b[32m3.0F\u001b[0m,\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36mdata1\u001b[0m: \u001b[32mArray\u001b[0m[\u001b[32mFloat\u001b[0m] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val params = Map(\n",
    "      \"image\" -> \"data/train-images-idx3-ubyte\",\n",
    "      \"label\" -> \"data/train-labels-idx1-ubyte\",\n",
    "      \"data_shape\" -> \"(784,)\",\n",
    "      \"batch_size\" -> \"100\",\n",
    "      \"shuffle\" -> \"1\",\n",
    "      \"flat\" -> \"1\",\n",
    "      \"silent\" -> \"0\",\n",
    "      \"seed\" -> \"10\"\n",
    "    )\n",
    "\n",
    "    val mnistPack = IO.MNISTPack(params)\n",
    "\n",
    "    val nBatch = 600\n",
    "    var batchCount = 0\n",
    "    for(batch <- mnistPack) {\n",
    "      batchCount += 1\n",
    "    }\n",
    "\n",
    "    // create DataIter\n",
    "    val mnistIter = mnistPack.iterator\n",
    "    // get the name and shape of data provided by this iterator \n",
    "    val provideData = mnistIter.provideData\n",
    "    // get the name and shape of label provided by this iterator \n",
    "    val provideLabel = mnistIter.provideLabel\n",
    "     \n",
    "    // reset the iterator\n",
    "    mnistIter.reset()\n",
    "    batchCount = 0\n",
    "    // check if iterator has next batch of data\n",
    "    while (mnistIter.hasNext) {\n",
    "      mnistIter.next()\n",
    "      batchCount += 1\n",
    "    }\n",
    " \n",
    "    mnistIter.reset()\n",
    "    // get next data batch from iterator\n",
    "    mnistIter.next()\n",
    "    // get label of current batch\n",
    "    val label0 = mnistIter.getLabel().head.toArray\n",
    "    // get data of current batch\n",
    "    val data0 = mnistIter.getData().head.toArray\n",
    "    mnistIter.next()\n",
    "    mnistIter.next()\n",
    "    mnistIter.next()\n",
    "    mnistIter.reset()\n",
    "    mnistIter.next()\n",
    "    val label1 = mnistIter.getLabel().head.toArray\n",
    "    val data1 = mnistIter.getData().head.toArray\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageRecordIter\n",
    "ImageRecordIter is for iterating on image RecordIO files\n",
    "It read images batches from RecordIO files with a rich of data augmentation options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mparams\u001b[0m: \u001b[32mMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mString\u001b[0m] = \u001b[33mMap\u001b[0m(\n",
       "  \u001b[32m\"prefetch_buffer\"\u001b[0m -> \u001b[32m\"1\"\u001b[0m,\n",
       "  \u001b[32m\"path_imgrec\"\u001b[0m -> \u001b[32m\"data/cifar/train.rec\"\u001b[0m,\n",
       "  \u001b[32m\"mean_img\"\u001b[0m -> \u001b[32m\"data/cifar/cifar10_mean.bin\"\u001b[0m,\n",
       "  \u001b[32m\"and_mirror\"\u001b[0m -> \u001b[32m\"False\"\u001b[0m,\n",
       "  \u001b[32m\"shuffle\"\u001b[0m -> \u001b[32m\"False\"\u001b[0m,\n",
       "  \u001b[32m\"preprocess_threads\"\u001b[0m -> \u001b[32m\"4\"\u001b[0m,\n",
       "  \u001b[32m\"rand_crop\"\u001b[0m -> \u001b[32m\"False\"\u001b[0m,\n",
       "  \u001b[32m\"data_shape\"\u001b[0m -> \u001b[32m\"(3,28,28)\"\u001b[0m,\n",
       "  \u001b[32m\"batch_size\"\u001b[0m -> \u001b[32m\"100\"\u001b[0m\n",
       ")\n",
       "\u001b[36mimgRecIter\u001b[0m: \u001b[32mDataIter\u001b[0m = non-empty iterator\n",
       "\u001b[36mnBatch\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m500\u001b[0m\n",
       "\u001b[36mbatchCount\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m500\u001b[0m\n",
       "\u001b[36mprovideData\u001b[0m: \u001b[32mListMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mShape\u001b[0m] = \u001b[33mMap\u001b[0m(\u001b[32m\"data\"\u001b[0m -> (100,3,28,28))\n",
       "\u001b[36mprovideLabel\u001b[0m: \u001b[32mListMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mShape\u001b[0m] = \u001b[33mMap\u001b[0m(\u001b[32m\"label\"\u001b[0m -> (100))\n",
       "\u001b[36mres9_9\u001b[0m: \u001b[32mDataBatch\u001b[0m = ml.dmlc.mxnet.DataBatch@5233832d\n",
       "\u001b[36mlabel0\u001b[0m: \u001b[32mArray\u001b[0m[\u001b[32mFloat\u001b[0m] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[32m2.0F\u001b[0m,\n",
       "  \u001b[32m3.0F\u001b[0m,\n",
       "  \u001b[32m7.0F\u001b[0m,\n",
       "  \u001b[32m6.0F\u001b[0m,\n",
       "  \u001b[32m2.0F\u001b[0m,\n",
       "  \u001b[32m1.0F\u001b[0m,\n",
       "  \u001b[32m7.0F\u001b[0m,\n",
       "  \u001b[32m9.0F\u001b[0m,\n",
       "  \u001b[32m6.0F\u001b[0m,\n",
       "  \u001b[32m2.0F\u001b[0m,\n",
       "  \u001b[32m2.0F\u001b[0m,\n",
       "  \u001b[32m5.0F\u001b[0m,\n",
       "  \u001b[32m4.0F\u001b[0m,\n",
       "  \u001b[32m5.0F\u001b[0m,\n",
       "  \u001b[32m4.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m1.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36mdata0\u001b[0m: \u001b[32mArray\u001b[0m[\u001b[32mFloat\u001b[0m] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[32m11.52652F\u001b[0m,\n",
       "  \u001b[32m10.147156F\u001b[0m,\n",
       "  \u001b[32m8.638443F\u001b[0m,\n",
       "  \u001b[32m7.039444F\u001b[0m,\n",
       "  \u001b[32m6.5186005F\u001b[0m,\n",
       "  \u001b[32m5.9982452F\u001b[0m,\n",
       "  \u001b[32m6.3482666F\u001b[0m,\n",
       "  \u001b[32m6.867447F\u001b[0m,\n",
       "  \u001b[32m6.450226F\u001b[0m,\n",
       "  \u001b[32m6.224579F\u001b[0m,\n",
       "  \u001b[32m5.1456604F\u001b[0m,\n",
       "  \u001b[32m5.121048F\u001b[0m,\n",
       "  \u001b[32m6.208969F\u001b[0m,\n",
       "  \u001b[32m7.3796997F\u001b[0m,\n",
       "  \u001b[32m7.333359F\u001b[0m,\n",
       "  \u001b[32m7.2532196F\u001b[0m,\n",
       "  \u001b[32m6.3181F\u001b[0m,\n",
       "  \u001b[32m5.5006866F\u001b[0m,\n",
       "  \u001b[32m6.7429657F\u001b[0m,\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val params = Map(\n",
    "      \"path_imgrec\" -> \"data/cifar/train.rec\",\n",
    "      \"mean_img\" -> \"data/cifar/cifar10_mean.bin\",\n",
    "      \"rand_crop\" -> \"False\",\n",
    "      \"rand_mirror\" -> \"False\",\n",
    "      \"shuffle\" -> \"False\",\n",
    "      \"data_shape\" -> \"(3,28,28)\",\n",
    "      \"batch_size\" -> \"100\",\n",
    "      \"preprocess_threads\" -> \"4\",\n",
    "      \"prefetch_buffer\" -> \"1\"\n",
    "    )\n",
    "    val imgRecIter = IO.ImageRecordIter(params)\n",
    "    val nBatch = 500\n",
    "    var batchCount = 0\n",
    "    // test provideData\n",
    "    val provideData = imgRecIter.provideData\n",
    "    val provideLabel = imgRecIter.provideLabel\n",
    "    \n",
    "    // Reset the iterator\n",
    "    imgRecIter.reset()\n",
    "    while (imgRecIter.hasNext) {\n",
    "      imgRecIter.next()\n",
    "      batchCount += 1\n",
    "    }\n",
    "\n",
    "    imgRecIter.reset()\n",
    "    // Get next batch of iterator\n",
    "    imgRecIter.next()\n",
    "    // Get label of current batch\n",
    "    val label0 = imgRecIter.getLabel().head.toArray\n",
    "    // Get data of current batch\n",
    "    val data0 = imgRecIter.getData().head.toArray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResizeIter\n",
    "Resize a DataIter to given number of batches per epoch. May produce incomplete batch in the middle of an epoch due to padding from internal iterator.\n",
    "\n",
    "It takes input arguments **dataIter**(Internal data iterator), **reSize**(number of batches per epoch to resize to) and **resetInternal**(whether to reset internal iterator on ResizeIter.reset) and returns resizeIterator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mml.dmlc.mxnet.io.{NDArrayIter, ResizeIter, PrefetchingIter}\u001b[0m\n",
       "\u001b[36mparams\u001b[0m: \u001b[32mMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mString\u001b[0m] = \u001b[33mMap\u001b[0m(\n",
       "  \u001b[32m\"silent\"\u001b[0m -> \u001b[32m\"0\"\u001b[0m,\n",
       "  \u001b[32m\"seed\"\u001b[0m -> \u001b[32m\"10\"\u001b[0m,\n",
       "  \u001b[32m\"flat\"\u001b[0m -> \u001b[32m\"1\"\u001b[0m,\n",
       "  \u001b[32m\"image\"\u001b[0m -> \u001b[32m\"data/train-images-idx3-ubyte\"\u001b[0m,\n",
       "  \u001b[32m\"label\"\u001b[0m -> \u001b[32m\"data/train-labels-idx1-ubyte\"\u001b[0m,\n",
       "  \u001b[32m\"shuffle\"\u001b[0m -> \u001b[32m\"1\"\u001b[0m,\n",
       "  \u001b[32m\"data_shape\"\u001b[0m -> \u001b[32m\"(784,)\"\u001b[0m,\n",
       "  \u001b[32m\"batch_size\"\u001b[0m -> \u001b[32m\"100\"\u001b[0m\n",
       ")\n",
       "\u001b[36mmnistIter\u001b[0m: \u001b[32mDataIter\u001b[0m = non-empty iterator\n",
       "\u001b[36mnBatch\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m400\u001b[0m\n",
       "\u001b[36mbatchCount\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m400\u001b[0m\n",
       "\u001b[36mresizeIter\u001b[0m: \u001b[32mio\u001b[0m.\u001b[32mResizeIter\u001b[0m = empty iterator"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ml.dmlc.mxnet.io.{NDArrayIter, ResizeIter, PrefetchingIter}\n",
    "\n",
    "val params = Map(\n",
    "      \"image\" -> \"data/train-images-idx3-ubyte\",\n",
    "      \"label\" -> \"data/train-labels-idx1-ubyte\",\n",
    "      \"data_shape\" -> \"(784,)\",\n",
    "      \"batch_size\" -> \"100\",\n",
    "      \"shuffle\" -> \"1\",\n",
    "      \"flat\" -> \"1\",\n",
    "      \"silent\" -> \"0\",\n",
    "      \"seed\" -> \"10\"\n",
    "    )\n",
    "\n",
    "    val mnistIter = IO.MNISTIter(params)\n",
    "    val nBatch = 400\n",
    "    var batchCount = 0\n",
    "\n",
    "    // Resize a Mnist data iterator\n",
    "    val resizeIter = new ResizeIter(mnistIter, nBatch, false)\n",
    "\n",
    "    while(resizeIter.hasNext) {\n",
    "      resizeIter.next()\n",
    "      batchCount += 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PrefetchIter\n",
    "\n",
    "Performs pre-fetch for other data iterators. Takes one or more DataIters and combine them with prefetching.\n",
    "\n",
    "This iterator will create another thread to perform next() and then store the data in memory. It potentially accelerates the data read, at the cost of more memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mparams\u001b[0m: \u001b[32mMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mString\u001b[0m] = \u001b[33mMap\u001b[0m(\n",
       "  \u001b[32m\"silent\"\u001b[0m -> \u001b[32m\"0\"\u001b[0m,\n",
       "  \u001b[32m\"seed\"\u001b[0m -> \u001b[32m\"10\"\u001b[0m,\n",
       "  \u001b[32m\"flat\"\u001b[0m -> \u001b[32m\"1\"\u001b[0m,\n",
       "  \u001b[32m\"image\"\u001b[0m -> \u001b[32m\"data/train-images-idx3-ubyte\"\u001b[0m,\n",
       "  \u001b[32m\"label\"\u001b[0m -> \u001b[32m\"data/train-labels-idx1-ubyte\"\u001b[0m,\n",
       "  \u001b[32m\"shuffle\"\u001b[0m -> \u001b[32m\"1\"\u001b[0m,\n",
       "  \u001b[32m\"data_shape\"\u001b[0m -> \u001b[32m\"(784,)\"\u001b[0m,\n",
       "  \u001b[32m\"batch_size\"\u001b[0m -> \u001b[32m\"100\"\u001b[0m\n",
       ")\n",
       "\u001b[36mmnistPack1\u001b[0m: \u001b[32mDataPack\u001b[0m = \u001b[33mMXDataPack\u001b[0m(\n",
       "  ml.dmlc.mxnet.DataBatch@206a0ce5,\n",
       "  ml.dmlc.mxnet.DataBatch@19b9b2f4,\n",
       "  ml.dmlc.mxnet.DataBatch@60961087,\n",
       "  ml.dmlc.mxnet.DataBatch@aa498fd,\n",
       "  ml.dmlc.mxnet.DataBatch@7ad9b068,\n",
       "  ml.dmlc.mxnet.DataBatch@2e2383d5,\n",
       "  ml.dmlc.mxnet.DataBatch@7ee1acbe,\n",
       "  ml.dmlc.mxnet.DataBatch@50acb0ef,\n",
       "  ml.dmlc.mxnet.DataBatch@67411062,\n",
       "  ml.dmlc.mxnet.DataBatch@55ce1a74,\n",
       "  ml.dmlc.mxnet.DataBatch@2639c82f,\n",
       "  ml.dmlc.mxnet.DataBatch@13272fcf,\n",
       "  ml.dmlc.mxnet.DataBatch@7c0aefc9,\n",
       "  ml.dmlc.mxnet.DataBatch@59325786,\n",
       "  ml.dmlc.mxnet.DataBatch@31a2843f,\n",
       "  ml.dmlc.mxnet.DataBatch@1bd18c93,\n",
       "  ml.dmlc.mxnet.DataBatch@300e5c87,\n",
       "  ml.dmlc.mxnet.DataBatch@7bcba367,\n",
       "  ml.dmlc.mxnet.DataBatch@5e6d435d,\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36mmnistPack2\u001b[0m: \u001b[32mDataPack\u001b[0m = \u001b[33mMXDataPack\u001b[0m(\n",
       "  ml.dmlc.mxnet.DataBatch@1f423ad2,\n",
       "  ml.dmlc.mxnet.DataBatch@3bd5463b,\n",
       "  ml.dmlc.mxnet.DataBatch@35e15e6d,\n",
       "  ml.dmlc.mxnet.DataBatch@377e824,\n",
       "  ml.dmlc.mxnet.DataBatch@dedd632,\n",
       "  ml.dmlc.mxnet.DataBatch@1c18ad2a,\n",
       "  ml.dmlc.mxnet.DataBatch@23b58af2,\n",
       "  ml.dmlc.mxnet.DataBatch@1f3f6068,\n",
       "  ml.dmlc.mxnet.DataBatch@7c0079fb,\n",
       "  ml.dmlc.mxnet.DataBatch@25a8faac,\n",
       "  ml.dmlc.mxnet.DataBatch@2a4516f1,\n",
       "  ml.dmlc.mxnet.DataBatch@4e9d1ff1,\n",
       "  ml.dmlc.mxnet.DataBatch@312d7878,\n",
       "  ml.dmlc.mxnet.DataBatch@53b2996b,\n",
       "  ml.dmlc.mxnet.DataBatch@51c2ef72,\n",
       "  ml.dmlc.mxnet.DataBatch@7706102c,\n",
       "  ml.dmlc.mxnet.DataBatch@2db2580c,\n",
       "  ml.dmlc.mxnet.DataBatch@6a8cf510,\n",
       "  ml.dmlc.mxnet.DataBatch@2c732e4c,\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36mnBatch\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m600\u001b[0m\n",
       "\u001b[36mbatchCount\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m600\u001b[0m\n",
       "\u001b[36mmnistIter1\u001b[0m: \u001b[32mDataIter\u001b[0m = non-empty iterator\n",
       "\u001b[36mmnistIter2\u001b[0m: \u001b[32mDataIter\u001b[0m = non-empty iterator\n",
       "\u001b[36mprefetchIter\u001b[0m: \u001b[32mPrefetchingIter\u001b[0m = non-empty iterator\n",
       "\u001b[36mprovideData\u001b[0m: \u001b[32mListMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mShape\u001b[0m] = \u001b[33mMap\u001b[0m(\u001b[32m\"data1\"\u001b[0m -> (100,784), \u001b[32m\"data2\"\u001b[0m -> (100,784))\n",
       "\u001b[36mprovideLabel\u001b[0m: \u001b[32mListMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mShape\u001b[0m] = \u001b[33mMap\u001b[0m(\u001b[32m\"label1\"\u001b[0m -> (100), \u001b[32m\"label2\"\u001b[0m -> (100))\n",
       "\u001b[36mres11_12\u001b[0m: \u001b[32mDataBatch\u001b[0m = ml.dmlc.mxnet.DataBatch@1941f220\n",
       "\u001b[36mlabel0\u001b[0m: \u001b[32mArray\u001b[0m[\u001b[32mFloat\u001b[0m] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[32m7.0F\u001b[0m,\n",
       "  \u001b[32m3.0F\u001b[0m,\n",
       "  \u001b[32m5.0F\u001b[0m,\n",
       "  \u001b[32m2.0F\u001b[0m,\n",
       "  \u001b[32m3.0F\u001b[0m,\n",
       "  \u001b[32m7.0F\u001b[0m,\n",
       "  \u001b[32m1.0F\u001b[0m,\n",
       "  \u001b[32m7.0F\u001b[0m,\n",
       "  \u001b[32m9.0F\u001b[0m,\n",
       "  \u001b[32m5.0F\u001b[0m,\n",
       "  \u001b[32m6.0F\u001b[0m,\n",
       "  \u001b[32m4.0F\u001b[0m,\n",
       "  \u001b[32m3.0F\u001b[0m,\n",
       "  \u001b[32m7.0F\u001b[0m,\n",
       "  \u001b[32m5.0F\u001b[0m,\n",
       "  \u001b[32m8.0F\u001b[0m,\n",
       "  \u001b[32m5.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m3.0F\u001b[0m,\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36mdata0\u001b[0m: \u001b[32mArray\u001b[0m[\u001b[32mFloat\u001b[0m] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "  \u001b[32m0.0F\u001b[0m,\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val params = Map(\n",
    "      \"image\" -> \"data/train-images-idx3-ubyte\",\n",
    "      \"label\" -> \"data/train-labels-idx1-ubyte\",\n",
    "      \"data_shape\" -> \"(784,)\",\n",
    "      \"batch_size\" -> \"100\",\n",
    "      \"shuffle\" -> \"1\",\n",
    "      \"flat\" -> \"1\",\n",
    "      \"silent\" -> \"0\",\n",
    "      \"seed\" -> \"10\"\n",
    "    )\n",
    "\n",
    "    val mnistPack1 = IO.MNISTPack(params)\n",
    "    val mnistPack2 = IO.MNISTPack(params)\n",
    "\n",
    "    val nBatch = 600\n",
    "    var batchCount = 0\n",
    "\n",
    "    val mnistIter1 = mnistPack1.iterator\n",
    "    val mnistIter2 = mnistPack2.iterator\n",
    "\n",
    "    var prefetchIter = new PrefetchingIter(\n",
    "        IndexedSeq(mnistIter1, mnistIter2),\n",
    "        IndexedSeq(Map(\"data\" -> \"data1\"), Map(\"data\" -> \"data2\")),\n",
    "        IndexedSeq(Map(\"label\" -> \"label1\"), Map(\"label\" -> \"label2\"))\n",
    "    )\n",
    "\n",
    "    // Check for next batch\n",
    "    while(prefetchIter.hasNext) {\n",
    "      prefetchIter.next()\n",
    "      batchCount += 1\n",
    "    }\n",
    "\n",
    "    // The name and shape of data provided by this iterator\n",
    "    val provideData = prefetchIter.provideData\n",
    "    // The name and shape of label provided by this iterator\n",
    "    val provideLabel = prefetchIter.provideLabel\n",
    "\n",
    "    prefetchIter.reset()\n",
    "    prefetchIter.next()\n",
    "    val label0 = prefetchIter.getLabel().head.toArray\n",
    "    val data0 = prefetchIter.getData().head.toArray\n",
    "\n",
    "    prefetchIter.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDArrayIter\n",
    "\n",
    "NDArrayIter is for iterating on NDArray. NDArray is a basic ndarray/Tensor like data structure in mxnet. \n",
    "It takes following parameters:\n",
    "- **data**(NDArrayIter supports single or multiple data and label)\n",
    "- **label**(Same as data, but is not fed to the model during testing)\n",
    "- **dataBatchSize**(Batch Size)\n",
    "- **shuffle**(Whether to shuffle the data) \n",
    "- **lastBatchHandle** (\"pad\", \"discard\" or \"roll_over\").- How to handle the last batch.\n",
    "\n",
    "This iterator will pad, discard or roll over the last batch if the size of data does not match batch_size. Roll over is intended for training and can cause problems if used for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mshape0\u001b[0m: \u001b[32mShape\u001b[0m = (1000,2,2)\n",
       "\u001b[36mdata\u001b[0m: \u001b[32mIndexedSeq\u001b[0m[\u001b[32mNDArray\u001b[0m] = \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@bc757ea0, ml.dmlc.mxnet.NDArray@a1db81b0)\n",
       "\u001b[36mshape1\u001b[0m: \u001b[32mShape\u001b[0m = (1000,1)\n",
       "\u001b[36mlabel\u001b[0m: \u001b[32mIndexedSeq\u001b[0m[\u001b[32mNDArray\u001b[0m] = \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@fc450a2b)\n",
       "\u001b[36mbatchData0\u001b[0m: \u001b[32mNDArray\u001b[0m = ml.dmlc.mxnet.NDArray@137c6494\n",
       "\u001b[36mbatchData1\u001b[0m: \u001b[32mNDArray\u001b[0m = ml.dmlc.mxnet.NDArray@4ea5965d\n",
       "\u001b[36mbatchLabel\u001b[0m: \u001b[32mNDArray\u001b[0m = ml.dmlc.mxnet.NDArray@85e2cd0f\n",
       "\u001b[36mdataIter0\u001b[0m: \u001b[32mNDArrayIter\u001b[0m = empty iterator\n",
       "\u001b[36mbatchCount\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m7\u001b[0m\n",
       "\u001b[36mnBatch0\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m8\u001b[0m\n",
       "\u001b[36mdataIter1\u001b[0m: \u001b[32mNDArrayIter\u001b[0m = empty iterator\n",
       "\u001b[36mnBatch1\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m7\u001b[0m\n",
       "\u001b[36mdataIter2\u001b[0m: \u001b[32mNDArrayIter\u001b[0m = empty iterator"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val shape0 = Shape(Array(1000, 2, 2))\n",
    "    val data = IndexedSeq(NDArray.ones(shape0), NDArray.zeros(shape0))\n",
    "    val shape1 = Shape(Array(1000, 1))\n",
    "    val label = IndexedSeq(NDArray.ones(shape1))\n",
    "    val batchData0 = NDArray.ones(Shape(Array(128, 2, 2)))\n",
    "    val batchData1 = NDArray.zeros(Shape(Array(128, 2, 2)))\n",
    "    val batchLabel = NDArray.ones(Shape(Array(128, 1)))\n",
    "\n",
    "    // lastBatchHandle = pad\n",
    "    val dataIter0 = new NDArrayIter(data, label, 128, false, \"pad\")\n",
    "    var batchCount = 0\n",
    "    val nBatch0 = 8\n",
    "    while(dataIter0.hasNext) {\n",
    "      val tBatch = dataIter0.next()\n",
    "      batchCount += 1\n",
    "     }\n",
    "\n",
    "    // lastBatchHandle = discard\n",
    "    val dataIter1 = new NDArrayIter(data, label, 128, false, \"discard\")\n",
    "    val nBatch1 = 7\n",
    "    batchCount = 0\n",
    "    while(dataIter1.hasNext) {\n",
    "      val tBatch = dataIter1.next()\n",
    "      batchCount += 1\n",
    "    }\n",
    "\n",
    "    // empty label (for prediction)\n",
    "    val dataIter2 = new NDArrayIter(data = data, dataBatchSize = 128, lastBatchHandle = \"discard\")\n",
    "    batchCount = 0\n",
    "    while(dataIter2.hasNext) {\n",
    "      val tBatch = dataIter2.next()\n",
    "      batchCount += 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "Iterators can be implemented in either C++ or front-end languages such as Python. The C++ definition is at [include/mxnet/io.h](https://github.com/dmlc/mxnet/blob/master/include/mxnet/io.h), all C++ implementations are located in [src/io](https://github.com/dmlc/mxnet/tree/master/src/io). These implementations heavily rely on [dmlc-core](https://github.com/dmlc/dmlc-core), which supports reading data from various data format and filesystems.\n",
    "\n",
    "## Further Readings\n",
    "- [Data loading API](http://mxnet.io/api/scala/io.html)\n",
    "- [Design of efficient data format](http://mxnet.io/architecture/note_data_loading.html)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
