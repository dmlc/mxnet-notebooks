{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Data IO\n",
    "This tutorial explains how to prepare, load and train with image data in MXNet. All IO in MXNet is handled via IO.DataIter and its subclasses, which is explained [here](https://github.com/dmlc/mxnet-notebooks/blob/master/scala/basic/data.ipynb). In this tutorial we focus on how to use pre-built data iterators as while as custom iterators to process image data.\n",
    "\n",
    "There are mainly three ways of loading image data in MXNet:\n",
    "- IO.ImageRecordIter: implemented in backend (C++), less customizable but can be used in all language bindings, load from .rec files\n",
    "- Custom iterator by inheriting IO.DataIter\n",
    "\n",
    "First, we explain the record io file format used by mxnet:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Scala kernel\n",
    "Add mxnet scala jar which is created as a part of MXNet Scala package installation in classpath as follows:\n",
    "\n",
    "**Note**: Process to add this jar in your scala kernel classpath can differ according to the scala kernel you are using.\n",
    "\n",
    "We have used [jupyter-scala kernel](https://github.com/alexarchambault/jupyter-scala) for creating this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "classpath.addPath(<path_to_jar>)\n",
    "\n",
    "e.g\n",
    "classpath.addPath(\"mxnet-full_2.11-osx-x86_64-cpu-0.1.2-SNAPSHOT.jar\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecordIO\n",
    "Record IO is the main file format used by MXNet for data IO. It supports reading and writing on various file systems including distributed file systems like Hadoop HDFS and AWS S3. First, we download the Caltech 101 dataset that contains 101 classes of objects and convert them into record io format:\n",
    "\n",
    "Download and unzip the Image Dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mMXNET_HOME\u001b[0m: \u001b[32mString\u001b[0m = \u001b[32m\"/home/ec2-user/src/mxnet\"\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// change this to your mxnet location\n",
    "val MXNET_HOME = \"/home/ec2-user/src/mxnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36msys.process._\u001b[0m\n",
       "\u001b[36mres2_1\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m0\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys.process._\n",
    "\"wget http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz -P data/ -q\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres3\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m0\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"tar -xzf data/101_ObjectCategories.tar.gz -C data/\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data. As you can see, under the root folder every category has a subfolder.\n",
    "\n",
    "Now let's convert them into record io format. First we need to make a list that contains all the image files and their categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BACKGROUND_Google 0\n",
      "Faces 1\n",
      "Faces_easy 2\n",
      "Leopards 3\n",
      "Motorbikes 4\n",
      "accordion 5\n",
      "airplanes 6\n",
      "anchor 7\n",
      "ant 8\n",
      "barrel 9\n",
      "bass 10\n",
      "beaver 11\n",
      "binocular 12\n",
      "bonsai 13\n",
      "brain 14\n",
      "brontosaurus 15\n",
      "buddha 16\n",
      "butterfly 17\n",
      "camera 18\n",
      "cannon 19\n",
      "car_side 20\n",
      "ceiling_fan 21\n",
      "cellphone 22\n",
      "chair 23\n",
      "chandelier 24\n",
      "cougar_body 25\n",
      "cougar_face 26\n",
      "crab 27\n",
      "crayfish 28\n",
      "crocodile 29\n",
      "crocodile_head 30\n",
      "cup 31\n",
      "dalmatian 32\n",
      "dollar_bill 33\n",
      "dolphin 34\n",
      "dragonfly 35\n",
      "electric_guitar 36\n",
      "elephant 37\n",
      "emu 38\n",
      "euphonium 39\n",
      "ewer 40\n",
      "ferry 41\n",
      "flamingo 42\n",
      "flamingo_head 43\n",
      "garfield 44\n",
      "gerenuk 45\n",
      "gramophone 46\n",
      "grand_piano 47\n",
      "hawksbill 48\n",
      "headphone 49\n",
      "hedgehog 50\n",
      "helicopter 51\n",
      "ibis 52\n",
      "inline_skate 53\n",
      "joshua_tree 54\n",
      "kangaroo 55\n",
      "ketch 56\n",
      "lamp 57\n",
      "laptop 58\n",
      "llama 59\n",
      "lobster 60\n",
      "lotus 61\n",
      "mandolin 62\n",
      "mayfly 63\n",
      "menorah 64\n",
      "metronome 65\n",
      "minaret 66\n",
      "nautilus 67\n",
      "octopus 68\n",
      "okapi 69\n",
      "pagoda 70\n",
      "panda 71\n",
      "pigeon 72\n",
      "pizza 73\n",
      "platypus 74\n",
      "pyramid 75\n",
      "revolver 76\n",
      "rhino 77\n",
      "rooster 78\n",
      "saxophone 79\n",
      "schooner 80\n",
      "scissors 81\n",
      "scorpion 82\n",
      "sea_horse 83\n",
      "snoopy 84\n",
      "soccer_ball 85\n",
      "stapler 86\n",
      "starfish 87\n",
      "stegosaurus 88\n",
      "stop_sign 89\n",
      "strawberry 90\n",
      "sunflower 91\n",
      "tick 92\n",
      "trilobite 93\n",
      "umbrella 94\n",
      "watch 95\n",
      "water_lilly 96\n",
      "wheelchair 97\n",
      "wild_cat 98\n",
      "windsor_chair 99\n",
      "wrench 100\n",
      "yin_yang 101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres4\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m0\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"python \"+MXNET_HOME+\"/tools/im2rec.py --list=1 --recursive=1 --shuffle=1 --test-ratio=0.2 data/caltech data/101_ObjectCategories\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting list file is in the format index\\t(one or more label)\\tpath. In this case there is only one label for each image but you can modify the list to add in more for multi label training.\n",
    "Then we can use this list to create our record io file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating .rec file from /home/ec2-user/mxnet-notebooks/scala/basic/data/caltech.lst in /home/ec2-user/mxnet-notebooks/scala/basic/data\n",
      "time: 0.00183486938477  count: 0\n",
      "time: 0.0827140808105  count: 1000\n",
      "time: 0.0803511142731  count: 2000\n",
      "time: 0.0845577716827  count: 3000\n",
      "time: 0.0807552337646  count: 4000\n",
      "time: 0.0814788341522  count: 5000\n",
      "time: 0.0812129974365  count: 6000\n",
      "time: 0.0810561180115  count: 7000\n",
      "time: 0.0805099010468  count: 8000\n",
      "time: 0.0889499187469  count: 9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres5\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m0\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"python \"+MXNET_HOME+\"/tools/im2rec.py --num-thread=4 --pass-through=1 data/caltech data/101_ObjectCategories\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The record io files are now generated in data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageRecordIter\n",
    "IO.ImageRecordIter can be used for loading image data saved in record io format. It is available in all frontend languages, but as it's implemented in C++, it is less flexible.\n",
    "\n",
    "To use ImageRecordIter, simply create an instance by loading your record file:\n",
    "\n",
    "**Parameters**\n",
    "- **path_imglist** (string, optional, default='') – Dataset Param: Path to image list.\n",
    "- **path_imgrec** (string, optional, default='./data/imgrec.rec') – Dataset Param: Path to image record file.\n",
    "- **aug_seq** (string, optional, default='aug_default') – Augmentation Param: the augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters.\n",
    "- **label_width** (int, optional, default='1') – Dataset Param: How many labels for an image.\n",
    "- **data_shape** (Shape(tuple), required) – Dataset Param: Shape of each instance generated by the DataIter.\n",
    "- **preprocess_threads** (int, optional, default='4') – Backend Param: Number of thread to do preprocessing.\n",
    "- **verbose** (boolean, optional, default=True) – Auxiliary Param: Whether to output parser information.\n",
    "- **num_parts** (int, optional, default='1') – partition the data into multiple parts\n",
    "- **part_index** (int, optional, default='0') – the index of the part will read\n",
    "- **shuffle_chunk_size** (long (non-negative), optional, default=0) – the size(MB) of the shuffle chunk, used with shuffle=True, it can enable global shuffling\n",
    "- **shuffle_chunk_seed** (int, optional, default='0') – the seed for chunk shuffling\n",
    "- **shuffle** (boolean, optional, default=False) – Augmentation Param: Whether to shuffle data.\n",
    "- **seed** (int, optional, default='0') – Augmentation Param: Random Seed.\n",
    "- **batch_size** (int (non-negative), required) – Batch Param: Batch size.\n",
    "- **round_batch** (boolean, optional, default=True) – Batch Param: Use round robin to handle overflow batch.\n",
    "- **prefetch_buffer** (long (non-negative), optional, default=4) – Backend Param: Number of prefetched parameters\n",
    "- **dtype** ({None, 'float16', 'float32', 'float64', 'int32', 'uint8'},optional, default='None') – Output data type. Leave as None to useinternal data iterator’s output type\n",
    "- **resize** (int, optional, default='-1') – Augmentation Param: scale shorter edge to size before applying other augmentations.\n",
    "- **rand_crop** (boolean, optional, default=False) – Augmentation Param: Whether to random crop on the image\n",
    "- **crop_y_start** (int, optional, default='-1') – Augmentation Param: Where to nonrandom crop on y.\n",
    "- **crop_x_start** (int, optional, default='-1') – Augmentation Param: Where to nonrandom crop on x.\n",
    "- **max_rotate_angle** (int, optional, default='0') – Augmentation Param: rotated randomly in [-max_rotate_angle, max_rotate_angle].\n",
    "- **max_aspect_ratio** (float, optional, default=0) – Augmentation Param: denotes the max ratio of random aspect ratio augmentation.\n",
    "- **max_shear_ratio** (float, optional, default=0) – Augmentation Param: denotes the max random shearing ratio.\n",
    "- **max_crop_size** (int, optional, default='-1') – Augmentation Param: Maximum crop size.\n",
    "- **min_crop_size** (int, optional, default='-1') – Augmentation Param: Minimum crop size.\n",
    "- **max_random_scale** (float, optional, default=1) – Augmentation Param: Maximum scale ratio.\n",
    "- **min_random_scale** (float, optional, default=1) – Augmentation Param: Minimum scale ratio.\n",
    "- **max_img_size** (float, optional, default=1e+10) – Augmentation Param: Maximum image size after resizing.\n",
    "- **min_img_size** (float, optional, default=0) – Augmentation Param: Minimum image size after resizing.\n",
    "- **random_h** (int, optional, default='0') – Augmentation Param: Maximum random value of H channel in HSL color space.\n",
    "- **random_s** (int, optional, default='0') – Augmentation Param: Maximum random value of S channel in HSL color space.\n",
    "- **random_l** (int, optional, default='0') – Augmentation Param: Maximum random value of L channel in HSL color space.\n",
    "- **rotate** (int, optional, default='-1') – Augmentation Param: Rotate angle.\n",
    "- **fill_value** (int, optional, default='255') – Augmentation Param: Filled color value while padding.\n",
    "- **inter_method** (int, optional, default='1') – Augmentation Param: 0-NN 1-bilinear 2-cubic 3-area 4-lanczos4 9-auto 10-rand.\n",
    "- **pad** (int, optional, default='0') – Augmentation Param: Padding size.\n",
    "- **mirror** (boolean, optional, default=False) – Augmentation Param: Whether to mirror the image.\n",
    "- **rand_mirror** (boolean, optional, default=False) – Augmentation Param: Whether to mirror the image randomly.\n",
    "- **mean_img** (string, optional, default='') – Augmentation Param: Mean Image to be subtracted.\n",
    "- **mean_r** (float, optional, default=0) – Augmentation Param: Mean value on R channel.\n",
    "- **mean_g** (float, optional, default=0) – Augmentation Param: Mean value on G channel.\n",
    "- **mean_b** (float, optional, default=0) – Augmentation Param: Mean value on B channel.\n",
    "- **mean_a** (float, optional, default=0) – Augmentation Param: Mean value on Alpha channel.\n",
    "- **scale** (float, optional, default=1) – Augmentation Param: Scale in color space.\n",
    "- **max_random_contrast** (float, optional, default=0) – Augmentation Param: Maximum ratio of contrast variation.\n",
    "- **max_random_illumination** (float, optional, default=0) – Augmentation Param: Maximum value of illumination variation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log4j:WARN No appenders could be found for logger (MXNetJVM).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mml.dmlc.mxnet._\u001b[0m\n",
       "\u001b[36mdataIter\u001b[0m: \u001b[32mml\u001b[0m.\u001b[32mdmlc\u001b[0m.\u001b[32mmxnet\u001b[0m.\u001b[32mDataIter\u001b[0m = non-empty iterator\n",
       "\u001b[36mbatch\u001b[0m: \u001b[32mml\u001b[0m.\u001b[32mdmlc\u001b[0m.\u001b[32mmxnet\u001b[0m.\u001b[32mDataBatch\u001b[0m = ml.dmlc.mxnet.DataBatch@1dee5185\n",
       "\u001b[36mdata\u001b[0m: \u001b[32mml\u001b[0m.\u001b[32mdmlc\u001b[0m.\u001b[32mmxnet\u001b[0m.\u001b[32mNDArray\u001b[0m = ml.dmlc.mxnet.NDArray@496baa2a"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ml.dmlc.mxnet._\n",
    "\n",
    "val dataIter = IO.ImageRecordIter(Map(\n",
    "    \"path_imgrec\" -> \"data/caltech.rec\", // the target record file\n",
    "    \"data_shape\" -> \"(3, 227, 227)\", // output data shape. An 227x227 region will be cropped from the original image.\n",
    "    \"batch_size\" -> \"4\", // number of samples per batch\n",
    "    \"resize\" -> \"256\" // resize the shorter edge to 256 before cropping\n",
    "    // ... you can add more augumentation options here. check above to see all possible choices\n",
    "    ))\n",
    "\n",
    "dataIter.reset()\n",
    "val batch = dataIter.next()\n",
    "val data = batch.data(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "- [Record IO](https://github.com/dmlc/mxnet-notebooks/tree/master/scala/basic/record_io_scala.ipynb) Read & Write RecordIO files with scala interface\n",
    "- [Advanced Image IO](https://github.com/dmlc/mxnet-notebooks/tree/master/scala/basic/advanced_img_io_scala.ipynb) Advanced image IO for detection, segmentation, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
