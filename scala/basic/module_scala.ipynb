{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Inference Module\n",
    "We modularized commonly used codes for training and inference in the module (or mod for short) package. This package provides intermediate-level and high-level interface for executing predefined networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Scala kernel\n",
    "Add mxnet scala jar which is created as a part of MXNet Scala package installation in classpath as follows:\n",
    "\n",
    "**Note**: Process to add this jar in your scala kernel classpath can differ according to the scala kernel you are using.\n",
    "\n",
    "We have used [jupyter-scala kernel](https://github.com/alexarchambault/jupyter-scala) for creating this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "classpath.addPath(<path_to_jar>)\n",
    "\n",
    "e.g\n",
    "classpath.addPath(\"mxnet-full_2.11-osx-x86_64-cpu-0.1.2-SNAPSHOT.jar\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "### Preliminary\n",
    "In this tutorial, we will use a simple multilayer perception for 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log4j:WARN No appenders could be found for logger (MXNetJVM).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mml.dmlc.mxnet._\u001b[0m\n",
       "\u001b[32mimport \u001b[36mml.dmlc.mxnet.module.{FitParams, Module}\u001b[0m\n",
       "\u001b[36mdata\u001b[0m: \u001b[32mml\u001b[0m.\u001b[32mdmlc\u001b[0m.\u001b[32mmxnet\u001b[0m.\u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@153695b4\n",
       "\u001b[36mfc1\u001b[0m: \u001b[32mml\u001b[0m.\u001b[32mdmlc\u001b[0m.\u001b[32mmxnet\u001b[0m.\u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@782359b1\n",
       "\u001b[36mact1\u001b[0m: \u001b[32mml\u001b[0m.\u001b[32mdmlc\u001b[0m.\u001b[32mmxnet\u001b[0m.\u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@69728e46\n",
       "\u001b[36mfc2\u001b[0m: \u001b[32mml\u001b[0m.\u001b[32mdmlc\u001b[0m.\u001b[32mmxnet\u001b[0m.\u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@6d9120e2\n",
       "\u001b[36msoftmax\u001b[0m: \u001b[32mml\u001b[0m.\u001b[32mdmlc\u001b[0m.\u001b[32mmxnet\u001b[0m.\u001b[32mSymbol\u001b[0m = ml.dmlc.mxnet.Symbol@659455de"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ml.dmlc.mxnet._\n",
    "import ml.dmlc.mxnet.module.{FitParams, Module}\n",
    "\n",
    "val data = Symbol.Variable(\"data\")\n",
    "val fc1 = Symbol.FullyConnected(name = \"fc1\")()(Map(\"data\" -> data, \"num_hidden\" -> 64))\n",
    "val act1 = Symbol.Activation(name = \"relu1\")()(Map(\"data\" -> fc1, \"act_type\" -> \"relu\"))\n",
    "val fc2 = Symbol.FullyConnected(name = \"fc2\")()(Map(\"data\" -> act1, \"num_hidden\" -> 10))\n",
    "val softmax = Symbol.SoftmaxOutput(name = \"softmax\")()(Map(\"data\" -> fc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create Module\n",
    "The most widely used module class is Module, which wraps a Symbol and one or more Executors.\n",
    "\n",
    "We construct a module by specify\n",
    "\n",
    "- symbol : the network Symbol\n",
    "- context : the device (or a list of devices) for execution\n",
    "- data_names : the list of data variable names\n",
    "- label_names : the list of label variable names\n",
    "\n",
    "One can refer to data.ipynb for more explanations about the last two arguments. Here we have only one data named data, and one label, with the name softmax_label, which is automatically named for us following the name softmax we specified for the SoftmaxOutput operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mml.dmlc.mxnet.optimizer.SGD\u001b[0m\n",
       "\u001b[36mmod\u001b[0m: \u001b[32mModule\u001b[0m = ml.dmlc.mxnet.module.Module@3110b89"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ml.dmlc.mxnet.optimizer.SGD\n",
    "\n",
    "val mod = new Module(softmax, contexts=Context.cpu(), dataNames=Array(\"data\"), labelNames=Array(\"softmax_label\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataIterator. Using Mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mbatchSize\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m2\u001b[0m\n",
       "\u001b[36mtrainIter\u001b[0m: \u001b[32mDataIter\u001b[0m = non-empty iterator\n",
       "\u001b[36mevalIter\u001b[0m: \u001b[32mDataIter\u001b[0m = non-empty iterator"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val batchSize=2\n",
    "\n",
    "val trainIter = IO.MNISTIter(Map(\n",
    "        \"image\" -> (\"data/train-images-idx3-ubyte\"),\n",
    "        \"label\" -> (\"data/train-labels-idx1-ubyte\"),\n",
    "        \"label_name\" -> \"softmax_label\",\n",
    "        \"input_shape\" -> \"(784,)\",\n",
    "        \"batch_size\" -> batchSize.toString,\n",
    "        \"shuffle\" -> \"True\",\n",
    "        \"flat\" -> \"True\", \"silent\" -> \"False\", \"seed\" -> \"10\"))\n",
    "val evalIter = IO.MNISTIter(Map(\n",
    "        \"image\" -> (\"data/t10k-images-idx3-ubyte\"),\n",
    "        \"label\" -> (\"data/t10k-labels-idx1-ubyte\"),\n",
    "        \"label_name\" -> \"softmax_label\",\n",
    "        \"input_shape\" -> \"(784,)\",\n",
    "        \"batch_size\" -> batchSize.toString,\n",
    "        \"flat\" -> \"True\", \"silent\" -> \"False\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Predict, and Evaluate\n",
    "Modules provide high-level APIs for training, predicting and evaluating. To fit a module, simply call the fit function with some DataIters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod.fit(trainIter, \n",
    "        evalData=scala.Option(evalIter),\n",
    "        fitParams = new FitParams().setOptimizer(new SGD(learningRate = 0.1f, momentum = 0.9f, wd = 0.0001f)),\n",
    "        numEpoch=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict with a module, simply call predict() with a DataIter. It will collect and return all the prediction results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36my\u001b[0m: \u001b[32mIndexedSeq\u001b[0m[\u001b[32mNDArray\u001b[0m] = \u001b[33mArrayBuffer\u001b[0m(\n",
       "  ml.dmlc.mxnet.NDArray@e4216872,\n",
       "  ml.dmlc.mxnet.NDArray@b6c053f0,\n",
       "  ml.dmlc.mxnet.NDArray@f3e68a11,\n",
       "  ml.dmlc.mxnet.NDArray@b04c5734,\n",
       "  ml.dmlc.mxnet.NDArray@e4635691,\n",
       "  ml.dmlc.mxnet.NDArray@38f232b,\n",
       "  ml.dmlc.mxnet.NDArray@f77fe955,\n",
       "  ml.dmlc.mxnet.NDArray@eef4e2b3,\n",
       "  ml.dmlc.mxnet.NDArray@e42c116c,\n",
       "  ml.dmlc.mxnet.NDArray@acf7250f,\n",
       "  ml.dmlc.mxnet.NDArray@e538781,\n",
       "  ml.dmlc.mxnet.NDArray@199fdaef,\n",
       "  ml.dmlc.mxnet.NDArray@cb3d9293,\n",
       "  ml.dmlc.mxnet.NDArray@eaf6f77c,\n",
       "  ml.dmlc.mxnet.NDArray@ca9ff00,\n",
       "  ml.dmlc.mxnet.NDArray@c406c5ef,\n",
       "  ml.dmlc.mxnet.NDArray@b670b4d8,\n",
       "  ml.dmlc.mxnet.NDArray@d9194c50,\n",
       "  ml.dmlc.mxnet.NDArray@2dd299,\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36mres7_1\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m5000\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val y = mod.predict(evalIter)\n",
    "y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another convenient API for prediction in the case where the prediction results might be too large to fit in the memory is `predictEveryBatch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36morg.slf4j.LoggerFactory\u001b[0m\n",
       "\u001b[36mpreds\u001b[0m: \u001b[32mIndexedSeq\u001b[0m[\u001b[32mIndexedSeq\u001b[0m[\u001b[32mNDArray\u001b[0m]] = \u001b[33mArrayBuffer\u001b[0m(\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@bd4d9298),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@ca6e5090),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@3168f3d),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@ca102191),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@cdc7d946),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@c1c349f4),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@c8a05432),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@de269f8b),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@374bbd4),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@ae8dfe32),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@c0b6a5dd),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@e5b6dacb),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@1f207ca7),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@f46b7260),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@cb95d452),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@a95649d4),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@ede813e7),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@b1c8980f),\n",
       "  \u001b[33mVector\u001b[0m(ml.dmlc.mxnet.NDArray@fcfea88b),\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.slf4j.LoggerFactory\n",
    "\n",
    "private val logger = LoggerFactory.getLogger(\"mnist\")   \n",
    "val preds = mod.predictEveryBatch(evalIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 accuracy 0.1135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36maccSum\u001b[0m: \u001b[32mFloat\u001b[0m = \u001b[32m1.0F\u001b[0m\n",
       "\u001b[36maccCnt\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m2\u001b[0m\n",
       "\u001b[36mi\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m1\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// perform prediction and calculate accuracy manually\n",
    "    evalIter.reset()\n",
    "    var accSum = 0.0f\n",
    "    var accCnt = 0\n",
    "    var i = 0\n",
    "    while (evalIter.hasNext) {\n",
    "              //println(\"hi\")\n",
    "\n",
    "      val batch = evalIter.next()\n",
    "      val predLabel: Array[Int] = NDArray.argmax_channel(preds(i)(0)).toArray.map(_.toInt)\n",
    "      val label = batch.label(0).toArray.map(_.toInt)\n",
    "      accSum += (predLabel zip label).map { case (py, y) =>\n",
    "        if (py == y) 1 else 0\n",
    "      }.sum\n",
    "      accCnt += predLabel.length\n",
    "      val (name, value) = mod.score(evalIter, new Accuracy).get\n",
    "      println(\"batch \" + i + \" accuracy \" + value)\n",
    "      i += 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36macc\u001b[0m: \u001b[32mEvalMetric\u001b[0m = ml.dmlc.mxnet.Accuracy@7055caf9\n",
       "\u001b[36mn\u001b[0m: \u001b[32mString\u001b[0m = \u001b[32m\"accuracy\"\u001b[0m\n",
       "\u001b[36mv\u001b[0m: \u001b[32mFloat\u001b[0m = \u001b[32m0.1135F\u001b[0m\n",
       "\u001b[36mres13_2\u001b[0m: (\u001b[32mString\u001b[0m, \u001b[32mFloat\u001b[0m) = \u001b[33m\u001b[0m(\u001b[32m\"accuracy\"\u001b[0m, \u001b[32m0.1135F\u001b[0m)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val acc = mod.score(evalIter, new Accuracy)\n",
    "val (n,v) = acc.get\n",
    "(n,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load\n",
    "We can save the module parameters in each training epoch by calling `setEpochEndCallback` method for `FitParams` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmodelPrefix\u001b[0m: \u001b[32mString\u001b[0m = \u001b[32m\"mx mlp\"\u001b[0m\n",
       "\u001b[36mmetric\u001b[0m: \u001b[32mAccuracy\u001b[0m = ml.dmlc.mxnet.Accuracy@1f90e6f6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// construct a callback function to save checkpoints\n",
    "val modelPrefix: String = \"mx mlp\"\n",
    "//val mod = new Module(softmax)\n",
    "val metric = new Accuracy()\n",
    "\n",
    "//val epoch: Int = 1\n",
    "for (epoch <- 0 until 5) {\n",
    " //   val checkpoint = mod.saveCheckpoint(modelPrefix, epoch, saveOptStates = true)\n",
    "    while (trainIter.hasNext) {\n",
    "        val batch = trainIter.next()\n",
    "        mod.forward(batch)\n",
    "        mod.updateMetric(metric, batch.label)\n",
    "        mod.backward()\n",
    "        mod.update()\n",
    "      }\n",
    "// saveOptStates = true means save optimizer states\n",
    "      val checkpoint = mod.saveCheckpoint(modelPrefix, epoch, saveOptStates = true)\n",
    "\n",
    "      val (name, value) = metric.get\n",
    "      metric.reset()\n",
    "      trainIter.reset()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To load the saved module parameters, call the `loadCheckpoint` function. You can specify cpu/gpu you want to use in Context and also workLoadList which helps in distributing work load on different cpus/gpus. \n",
    "\n",
    "`loadCheckpoint` function creates a module from previously saved checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mloadModelEpoch\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m2\u001b[0m\n",
       "\u001b[36mmod\u001b[0m: \u001b[32mModule\u001b[0m = ml.dmlc.mxnet.module.Module@7aaade12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Epoch to load\n",
    "val loadModelEpoch = 2\n",
    "// loadOptimizerStates = true only when checkpoint was saved with saveOptStates=True\n",
    "val mod = Module.loadCheckpoint(modelPrefix, loadModelEpoch, loadOptimizerStates = true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize parameters, Bind the symbols to construct executors first with `bind` method. Then, initialize the parameters and auxiliary states by calling `initParams()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod.bind(dataShapes = trainIter.provideData, labelShapes = Some(trainIter.provideLabel))\n",
    "mod.initParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get current parameters using `getParams` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36margParams\u001b[0m: \u001b[32mMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mNDArray\u001b[0m] = \u001b[33mMap\u001b[0m(\n",
       "  \u001b[32m\"fc1_weight\"\u001b[0m -> ml.dmlc.mxnet.NDArray@96840c2c,\n",
       "  \u001b[32m\"fc2_bias\"\u001b[0m -> ml.dmlc.mxnet.NDArray@367f5b1c,\n",
       "  \u001b[32m\"fc2_weight\"\u001b[0m -> ml.dmlc.mxnet.NDArray@34041eee,\n",
       "  \u001b[32m\"fc1_bias\"\u001b[0m -> ml.dmlc.mxnet.NDArray@ea1ecde3\n",
       ")\n",
       "\u001b[36mauxParams\u001b[0m: \u001b[32mMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mNDArray\u001b[0m] = \u001b[33mMap\u001b[0m()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val (argParams, auxParams) = mod.getParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, assign parameter and aux state values using `setParams` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod.setParams(argParams, auxParams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want to resume training from a saved checkpoint, instead of calling setParams(), we can directly call fit(), passing the loaded parameters, so that fit() knows to start from those parameters instead of initializing from random. We also set the beginEpoch so that so that fit() knows we are resuming from a previous saved epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mbeginEpoch\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m4\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val beginEpoch = 4\n",
    "mod.fit(trainIter, \n",
    "        evalData=scala.Option(evalIter),\n",
    "        fitParams=new FitParams().setArgParams(argParams).\n",
    "        setAuxParams(auxParams).setBeginEpoch(beginEpoch).\n",
    "        setOptimizer(new SGD(learningRate = 0.1f, momentum = 0.9f, wd = 0.0001f)),\n",
    "        numEpoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module as a computation \"machine\"\n",
    "We already seen how to module for basic training and inference. Now we are going to show a more flexiable usage of module.\n",
    "\n",
    "A module represents a computation component. The design purpose of a module is that it abstract a computation “machine”, that accpets Symbol programs and data, and then we can run forward, backward, update parameters, etc.\n",
    "\n",
    "We aim to make the APIs easy and flexible to use, especially in the case when we need to use imperative API to work with multiple modules (e.g. stochastic depth network).\n",
    "\n",
    "A module has several states:\n",
    "\n",
    "- **Initial state**. Memory is not allocated yet, not ready for computation yet.\n",
    "- **Binded**. Shapes for inputs, outputs, and parameters are all known, memory allocated, ready for computation.\n",
    "- **Parameter initialized**. For modules with parameters, doing computation before initializing the parameters might result in undefined outputs.\n",
    "- **Optimizer installed**. An optimizer can be installed to a module. After this, the parameters of the module can be updated according to the optimizer after gradients are computed (forward-backward).\n",
    "\n",
    "The following codes implement a simplified fit(). Here we used other components including initializer, optimizer, and metric, which are explained in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmod\u001b[0m: \u001b[32mModule\u001b[0m = ml.dmlc.mxnet.module.Module@27cbfc5\n",
       "\u001b[36mmetric\u001b[0m: \u001b[32mAccuracy\u001b[0m = ml.dmlc.mxnet.Accuracy@273f6196\n",
       "\u001b[36mname\u001b[0m: \u001b[32mString\u001b[0m = \u001b[32m\"accuracy\"\u001b[0m\n",
       "\u001b[36mvalue\u001b[0m: \u001b[32mFloat\u001b[0m = \u001b[32m0.10195F\u001b[0m\n",
       "\u001b[36mres26_7\u001b[0m: (\u001b[32mString\u001b[0m, \u001b[32mFloat\u001b[0m) = \u001b[33m\u001b[0m(\u001b[32m\"accuracy\"\u001b[0m, \u001b[32m0.10195F\u001b[0m)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// initial state\n",
    "val mod = new Module(softmax)\n",
    "\n",
    "// bind, tell the module the data and label shapes, so\n",
    "// that memory could be allocated on the devices for computation\n",
    "mod.bind(dataShapes=trainIter.provideData, labelShapes=Some(trainIter.provideLabel))\n",
    "\n",
    "// init parameters\n",
    "mod.initParams(initializer=new Xavier(magnitude = 2f))\n",
    "\n",
    "// init optimizer\n",
    "mod.initOptimizer(\"local\", new SGD(learningRate = 0.1f, momentum = 0.9f, wd = 0.0001f))\n",
    "\n",
    "// use accuracy as the metric\n",
    "val metric = new Accuracy\n",
    "\n",
    "// train one epoch, i.e. going over the data iter one pass\n",
    "while (trainIter.hasNext) {\n",
    "    val batch = trainIter.next()\n",
    "    mod.forward(batch)                     // compute predictions\n",
    "    mod.updateMetric(metric, batch.label)  // accumulate prediction accuracy\n",
    "    mod.backward()                         // compute gradients\n",
    "    mod.update()                           // update parameters using SGD\n",
    "}\n",
    "\n",
    "// training accuracy\n",
    "val (name, value) = metric.get\n",
    "(name, value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beside the operations, a module provides a lot of useful information.\n",
    "\n",
    "basic names:\n",
    "- **dataNames**: list of string indicating the names of the required data.\n",
    "- **outputNames**: list of string indicating the names of the outputs.\n",
    "\n",
    "state information\n",
    "- **binded**: bool, indicating whether the memory buffers needed for computation has been allocated.\n",
    "- **forTraining**: whether the module is binded for training (if binded).\n",
    "- **paramsInitialized**: bool, indicating whether the parameters of this modules has been initialized.\n",
    "- **optimizerInitialized**: bool, indicating whether an optimizer is defined and initialized.\n",
    "- **inputsNeedGrad**: bool, indicating whether gradients with respect to the input data is needed. Might be useful when implementing composition of modules.\n",
    "\n",
    "input/output information\n",
    "- **dataShapes**: a list of (name, shape). In theory, since the memory is allocated, we could directly provide the data arrays. But in the case of data parallelization, the data arrays might not be of the same shape as viewed from the external world.\n",
    "- **labelShapes**: a list of (name, shape). This might be [] if the module does not need labels (e.g. it does not contains a loss function at the top), or a module is not binded for training.\n",
    "- **outputShapes**: a list of (name, shape) for outputs of the module.\n",
    "\n",
    "parameters (for modules with parameters)\n",
    "- **getParams()**: return a tuple (argParams, auxParams). Each of those is a dictionary of name to NDArray mapping. Those NDArray always lives on CPU. The actual parameters used for computing might live on other devices (GPUs), this function will retrieve (a copy of) the latest parameters.\n",
    "- **getOutputs()**: get outputs of the previous forward operation.\n",
    "- **getInputGrads()**: get the gradients with respect to the inputs computed in the previous backward operation.\n",
    "\n",
    "setup\n",
    "- **bind()**: prepare environment for computation.\n",
    "- **initOptimizer()**: install optimizer for parameter updating.\n",
    "\n",
    "computation\n",
    "- **forward(dataBatch)**: forward operation.\n",
    "- **backward(outGrads=None)**: backward operation.\n",
    "- **update()**: update parameters according to installed optimizer.\n",
    "- **getOutputs()**: get outputs of the previous forward operation.\n",
    "- **getInputGrads()**: get the gradients with respect to the inputs computed in the previous backward operation.\n",
    "- **updateMetric(metric, labels)**: update performance metric for the previous forward computed results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres27_0\u001b[0m: (\u001b[32mIndexedSeq\u001b[0m[\u001b[32mDataDesc\u001b[0m], \u001b[32mIndexedSeq\u001b[0m[\u001b[32mDataDesc\u001b[0m], \u001b[32mIndexedSeq\u001b[0m[(\u001b[32mString\u001b[0m, \u001b[32mShape\u001b[0m)]) = \u001b[33m\u001b[0m(\n",
       "  \u001b[33mVector\u001b[0m(DataDesc[data,(2,784),Float32,NCHW]),\n",
       "  \u001b[33mVector\u001b[0m(DataDesc[softmax_label,(2),Float32,NCHW]),\n",
       "  \u001b[33mArrayBuffer\u001b[0m(\u001b[33m\u001b[0m(\u001b[32m\"softmax_output\"\u001b[0m, (2,10)))\n",
       ")\n",
       "\u001b[36mres27_1\u001b[0m: (\u001b[32mMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mNDArray\u001b[0m], \u001b[32mMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mNDArray\u001b[0m]) = \u001b[33m\u001b[0m(\n",
       "  \u001b[33mMap\u001b[0m(\n",
       "    \u001b[32m\"fc1_weight\"\u001b[0m -> ml.dmlc.mxnet.NDArray@a073e593,\n",
       "    \u001b[32m\"fc1_bias\"\u001b[0m -> ml.dmlc.mxnet.NDArray@15f069eb,\n",
       "    \u001b[32m\"fc2_weight\"\u001b[0m -> ml.dmlc.mxnet.NDArray@fb482814,\n",
       "    \u001b[32m\"fc2_bias\"\u001b[0m -> ml.dmlc.mxnet.NDArray@56ac2896\n",
       "  ),\n",
       "  \u001b[33mMap\u001b[0m()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(mod.dataShapes, mod.labelShapes, mod.outputShapes)\n",
    "mod.getParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on Modules\n",
    "Module simplifies the implementation of new modules. For example\n",
    "- [SequentialModule](https://github.com/dmlc/mxnet/blob/master/scala-package/core/src/main/scala/ml/dmlc/mxnet/module/SequentialModule.scala) can chain multiple modules together\n",
    "\n",
    "See also [examples](https://github.com/dmlc/mxnet/tree/master/scala-package/examples/src/main/scala/ml/dmlc/mxnet/examples/module) for a list of code examples using the module API.\n",
    "\n",
    "## Implementation\n",
    "The module is implemented in scala, located at [scala/mxnet/module](https://github.com/dmlc/mxnet/tree/master/scala-package/core/src/main/scala/ml/dmlc/mxnet/module)\n",
    "\n",
    "## Futher Readings\n",
    "[module API](http://mxnet.io/api/scala/docs/index.html#ml.dmlc.mxnet.module.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
