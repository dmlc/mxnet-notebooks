{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on Hand Written Digit Recognition\n",
    "\n",
    "In this tutorial we will go through the basic use case of MXNet and also touch on some advanced usages. This example is based on the MNIST dataset, which contains 70,000 images of hand written characters with 28-by-28 pixel size.\n",
    "\n",
    "This tutorial covers the following topics:\n",
    "- network definition.\n",
    "- Variable naming.\n",
    "- Basic data loading and training with feed-forward deep neural networks.\n",
    "- Monitoring intermediate outputs for debuging.\n",
    "- Custom training loop for advanced models.\n",
    "\n",
    "First let's import the modules and setup logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-02-28 12:06:53.284281. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Hardware \n",
    "CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-02-28 12:07:07.285214. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "context = mx.cpu(0)\n",
    "#context = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Definition\n",
    "Now we can start constructing our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-02-28 12:07:08.881956. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# Variables are place holders for input arrays. We give each variable a unique name.\n",
    "data = mx.symbol.Variable('data')\n",
    "\n",
    "# The input is fed to a fully connected layer that computes Y=WX+b.\n",
    "# This is the main computation module in the network.\n",
    "# Each layer also needs an unique name. We'll talk more about naming in the next section.\n",
    "fc1  = mx.symbol.FullyConnected(data = data, name='fc1', num_hidden=128)\n",
    "# Activation layers apply a non-linear function on the previous layer's output.\n",
    "# Here we use Rectified Linear Unit (ReLU) that computes Y = max(X, 0).\n",
    "act1 = mx.symbol.Activation(data = fc1, name='relu1', act_type=\"relu\")\n",
    "\n",
    "fc2  = mx.symbol.FullyConnected(data = act1, name = 'fc2', num_hidden = 64)\n",
    "act2 = mx.symbol.Activation(data = fc2, name='relu2', act_type=\"relu\")\n",
    "\n",
    "fc3  = mx.symbol.FullyConnected(data = act2, name='fc3', num_hidden=10)\n",
    "# Finally we have a loss layer that compares the network's output with label and generates gradient signals.\n",
    "mlp  = mx.symbol.SoftmaxOutput(data = fc3, name = 'softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the network we just defined with MXNet's visualization module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: plot Pages: 1 -->\n",
       "<svg width=\"214pt\" height=\"630pt\"\n",
       " viewBox=\"0.00 0.00 214.00 630.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 626)\">\n",
       "<title>plot</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-626 210,-626 210,4 -4,4\"/>\n",
       "<!-- data -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>data</title>\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"#000000\" cx=\"47\" cy=\"-29\" rx=\"47\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-24.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- fc1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>fc1</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"#000000\" points=\"94,-152 0,-152 0,-94 94,-94 94,-152\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-125.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">128</text>\n",
       "</g>\n",
       "<!-- fc1&#45;&gt;data -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>fc1&#45;&gt;data</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47,-83.6321C47,-75.1148 47,-66.2539 47,-58.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"47,-93.7731 42.5001,-83.773 47,-88.7731 47.0001,-83.7731 47.0001,-83.7731 47.0001,-83.7731 47,-88.7731 51.5001,-83.7731 47,-93.7731 47,-93.7731\"/>\n",
       "</g>\n",
       "<!-- relu1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>relu1</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"#000000\" points=\"94,-246 0,-246 0,-188 94,-188 94,-246\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-219.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-205.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">relu</text>\n",
       "</g>\n",
       "<!-- relu1&#45;&gt;fc1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>relu1&#45;&gt;fc1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47,-177.6321C47,-169.1148 47,-160.2539 47,-152.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"47,-187.7731 42.5001,-177.773 47,-182.7731 47.0001,-177.7731 47.0001,-177.7731 47.0001,-177.7731 47,-182.7731 51.5001,-177.7731 47,-187.7731 47,-187.7731\"/>\n",
       "</g>\n",
       "<!-- fc2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>fc2</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"#000000\" points=\"94,-340 0,-340 0,-282 94,-282 94,-340\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-313.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-299.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">64</text>\n",
       "</g>\n",
       "<!-- fc2&#45;&gt;relu1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>fc2&#45;&gt;relu1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47,-271.6321C47,-263.1148 47,-254.2539 47,-246.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"47,-281.7731 42.5001,-271.773 47,-276.7731 47.0001,-271.7731 47.0001,-271.7731 47.0001,-271.7731 47,-276.7731 51.5001,-271.7731 47,-281.7731 47,-281.7731\"/>\n",
       "</g>\n",
       "<!-- relu2 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>relu2</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"#000000\" points=\"94,-434 0,-434 0,-376 94,-376 94,-434\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-407.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-393.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">relu</text>\n",
       "</g>\n",
       "<!-- relu2&#45;&gt;fc2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>relu2&#45;&gt;fc2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47,-365.6321C47,-357.1148 47,-348.2539 47,-340.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"47,-375.7731 42.5001,-365.773 47,-370.7731 47.0001,-365.7731 47.0001,-365.7731 47.0001,-365.7731 47,-370.7731 51.5001,-365.7731 47,-375.7731 47,-375.7731\"/>\n",
       "</g>\n",
       "<!-- fc3 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>fc3</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"#000000\" points=\"94,-528 0,-528 0,-470 94,-470 94,-528\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-501.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-487.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">10</text>\n",
       "</g>\n",
       "<!-- fc3&#45;&gt;relu2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>fc3&#45;&gt;relu2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47,-459.6321C47,-451.1148 47,-442.2539 47,-434.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"47,-469.7731 42.5001,-459.773 47,-464.7731 47.0001,-459.7731 47.0001,-459.7731 47.0001,-459.7731 47,-464.7731 51.5001,-459.7731 47,-469.7731 47,-469.7731\"/>\n",
       "</g>\n",
       "<!-- softmax_label -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>softmax_label</title>\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"#000000\" cx=\"159\" cy=\"-499\" rx=\"47\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-494.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">softmax_label</text>\n",
       "</g>\n",
       "<!-- softmax -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>softmax</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"150,-622 56,-622 56,-564 150,-564 150,-622\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-588.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">softmax</text>\n",
       "</g>\n",
       "<!-- softmax&#45;&gt;fc3 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>softmax&#45;&gt;fc3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M80.3812,-555.0328C75.0542,-546.091 69.4571,-536.6959 64.401,-528.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"85.5882,-563.7731 76.6042,-557.4852 83.0292,-559.4776 80.4701,-555.1821 80.4701,-555.1821 80.4701,-555.1821 83.0292,-559.4776 84.3361,-552.8789 85.5882,-563.7731 85.5882,-563.7731\"/>\n",
       "</g>\n",
       "<!-- softmax&#45;&gt;softmax_label -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>softmax&#45;&gt;softmax_label</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M125.5712,-555.1126C131.3182,-545.4659 137.3825,-535.2865 142.7449,-526.2854\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"120.4118,-563.7731 121.6639,-552.8789 122.9708,-559.4776 125.5299,-555.1821 125.5299,-555.1821 125.5299,-555.1821 122.9708,-559.4776 129.3958,-557.4852 120.4118,-563.7731 120.4118,-563.7731\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x109770f50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-02-28 12:07:13.209212. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "mx.viz.plot_network(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Naming\n",
    "\n",
    "MXNet requires variable names to follow certain conventions:\n",
    "- All input arrays have a name. This includes inputs (data & label) and model parameters (weight, bias, etc).\n",
    "- Arrays can be renamed by creating named variable. Otherwise, a default name is given as 'SymbolName_ArrayName'. For example, FullyConnected symbol fc1's weight array is named as 'fc1_weight'.\n",
    "- Although you can also rename weight arrays with variables, weight array's name should always end with '_weight' and bias array '_bias'. MXNet relies on the suffixes of array names to correctly initialize & update them.\n",
    "\n",
    "Call list_arguments method on a symbol to get the names of all its inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'fc1_weight',\n",
       " 'fc1_bias',\n",
       " 'fc2_weight',\n",
       " 'fc2_bias',\n",
       " 'fc3_weight',\n",
       " 'fc3_bias',\n",
       " 'softmax_label']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-02-28 12:07:14.809285. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "mlp.list_arguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "We fetch and load the MNIST dataset and partition it into two sets: 60000 examples for training and 10000 examples for testing. We also visualize a few examples to get an idea of what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAA/CAYAAADwizNIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAE4lJREFUeJztnXtMFFcbxoeb4RouIdxMaoV8LRAbJE1Ka4MRY6OmRBMq\ntiCmlUpTC0pSUYw3WmkkGsUQzZpiDdggkKq1hUhNaq2oVARSpJZrue16YcEgl2VZFph5vj/sTtgr\ns7uzINv3l7wRYZh59pwzz5zznnMGBwAMQRAEsfBxnG8BBEEQhDiQoRMEQdgJZOgEQRB2Ahk6QRCE\nnUCGThAEYSeQoRMEQdgJZOgEQRB2Ahk6QRCEnUCGThAEYSc4z+XFHBwc5nxbKgAH0kE6SAfpsDcd\nhqAeOkEQhJ1Ahr6A8fDwYPLz85nh4eH5lkIQxEsAGfoCxMvLi/Hy8mJqamqYzMxMJikpab4lzSsp\nKSlMSkoKMz4+zgBgzpw5wwQEBMy3LIKYewDMWTAMAzHCx8cHk5OTUCgUePvtt00ea0sd5oSYOsrL\ny1FeXg4AGBwcnDcd3t7e8Pb2xr59+/DgwQMAAMdxuHr1Knx8fGyuY9GiRTh9+jQ4jtOLO3fuzHl5\nvCztg3T8N3QY1LYQDT07O5u/caVSKTw8PBZkhVhyno0bN4JlWbAsi9HRUYSEhMyLDldXVzQ1NaGp\nqcmgoT58+BDOzs420xEcHIwnT55oXbOnpwcZGRmQyWT466+/5rQ85rN9hIWFITMzE7W1tXr10NHR\ngW+++WbO28d8loepcHFxQXh4OMLDw+Hn5zcnOtra2tDW1oaEhAQkJCSAYRgkJCRAIpFAIpGgra0N\nGtra2gTrWBCGvmnTJgQHB5s8ZqahV1dX/2caqKurK1pbW3lDP3LkyLzdKKmpqXrm0dnZiZaWFgwN\nDYHjOLi7u9tER0hICGQyGX/d69ev4/r163B1dQXDvDD7P/74Y9ZRwly1D2dnZwQGBiIwMBAHDhzA\nlStX0N3djYiICKt1FBQUYGxsDCzLguM4/t+ZX7Msi6amJgQGBtq0PAICAnDjxg3U1taitrYW165d\nw7Vr1/Dmm2/OSztdtmwZGhoatKKlpYUvH7lcjoaGBnz//fdITExEYmIivvzyS1F1zDRroUgkEkHl\nYVCbtSZtTpj64KtXr4ZKpcL09DTu3r0LR0dHo8fOtaF7enqioaGBL/Dh4WHExcWZ1Ci2DmdnZ9y/\nfx8A+BvG3M8hVnkwDAMHBwdkZWUhKysLGRkZCA8P53vkZWVl4DgOu3fvFl1HSEgIHj16BI7joFar\nceDAATg6OurVRXBwsMmRm9jloRuxsbHYsWMH6urq0NzcbHAUMzQ0ZLGOoKAgVFZWYmxszOC5DYVc\nLrdJecTGxuK3336DXC43eF2VSoVz587ZvJ0uX74c2dnZ+OSTT8AwDLZt2ya4bGZqzcvLE6V9SCQS\nU75tFLsw9JkmzXGcydz4XBp6fHw8uru7wbIsBgYGMDAwwPeIhBiGWDqOHTsGABgYGICHh4dZ1xZT\nx8zw9/eHv78//Pz88N5774FhGJw+fRpTU1MYGRnBG2+8IaoOJycn1NXV8WaelJRkkW5rdNy8eRMy\nmQzFxcUoLi7GhQsX+K8rKipQUVEBpVKJyclJk8YxMDCA+vp6i3RER0fjwYMHer1wzb8aHRUVFZDL\n5Vo/i46OFq08XF1dkZOTA5VKxX+uuro6VFdX66V/VCoVtm7darN6iYmJwejoKDiOw8WLF8EwL+ZY\nWlpaoFAooFAoMDExgbGxMVRVVaGvrw8KhQLj4+N6dXPhwgVR7pfZDN3Qz+0m5aJr6IWFhUaPXbdu\nHaanp21u6KtXr8b4+DhYlsWTJ08QEBCAgIAAxMfHQ6lUzpmhb9q0CRzHQalUYsWKFRabl7U6XFxc\nkJOTg7Nnz+Lp06dQKpV8TE1NYXR0FFNTU7h3796s+UlLdEgkEt7MU1JSrCoHS3X09/eb3eubmc/O\nzc3F+vXr4eLiYpGOjRs3zqqhsrISlZWVSEpKwqpVq1BZWQmlUgmO43Dr1i3RymPz5s38NYeHh3H4\n8GF+lObk5ITY2FjExsbyKTi1Wo2goCDR6yU4OBgjIyO8lvT0dIPHRUVF6X0vMDAQ6enpaG1tRVdX\nF6qrq+Hl5SXK/ZKQkMCnXNra2vicuc7n1EKTYxdSHgvK0A0NOwwdO9uEj6UVsnbtWqhUKrAsi97e\nXr38o7u7O/7dMWYT49BEeHg4hoaGAAC5ubmCrye2DoZhcPnyZUHGdfLkSdF1REZG8j3Bb7/91upy\nsFTH7t27tT4rAINlMDExgebmZuzZswdpaWmi6dCkswz1zI3l0MfGxvhRpVqtxvLly0Upj3/++Qcc\nx6G8vBxubm5Gz6kZVXEcJ3gS3xwd27dv58+/b98+BAQEzFv7EBozzX42Mzem46U29KioKExNTfEV\nY2poqDH0wcHBWSdQLakQb29vPH36FCzLYmhoyGgjjIqKQnV1Naqrq22yTM/V1RU1NTUAgOrqarMe\nILZooDOH1roxMjICuVwOuVyO0dFRxMXFiabD2dkZ9fX1/HUM9bTmqjy2bNmi99lHR0dRVFSEtLQ0\npKWlISoqCqGhoaLr8PT01MpTS6VSvvcrNGpra0VbFTY5OYmsrKxZP1t8fLxNDV2z0ur27duCVq7M\n1f2iG5pVLoYwlmoxpeOlNvS33nqLN/SqqiqEh4cbPVZj6CqVCi0tLSbTM5ZUSGlpKViWxdTUlMHh\n2+LFi1FYWIiRkRF+xclsQ0lLdOTm5gIAZDKZoBUbYWFhyMvLw6uvvmqTBpqbmwuFQgGO49DQ0ICi\noiIUFRXh/fff1xrB/Prrr6IO7T/66CO+x7lp06ZZdS5duhQ///wzHzt37hRFR1JSEiYmJrQM8tix\nY1pDdEtDiI5Vq1Zp9cQZ5kXKYOXKlXzs2rXLZA5dY+pilIex1IZuzFwRZQtD7+vr48/f3t4OPz8/\nREREYNGiRYiJiUFYWBjCwsJsVi9CwlQ+3VQ2wpSOl9rQ09PT+QY3OjqKY8eOGT320KFDfA59YGAA\nxcXFolVIUFAQJicnwbIsP7miiZSUFKSkpEAmk2Fqaoo383v37s264sVcHc7Ozuju7gbHcdi+fbvR\n4xwdHfH555+jq6uLTwGYmpC0toE6OzvD2dnZ5Gjh/Pnzohp6aGgob0gHDx40ek4nJydkZmbyk2Oa\nmJqawnfffWe1jpnr3hUKBbZt22b2jW1NeRw9elTLuIScNzo6mk/TzIyCggKbtA+GYbB+/XrEx8cj\nNTUVqamp/EocAMjJyRGtPDShOwHb19cHlUqFzs5OrZRTTk4OYmJisHjxYlHrxVho1pobQ7M23VId\nL7Wh79u3T6tSTKVSZh4r9qRoSEgIb9QJCQlwc3NDTEwMLl68qDW5FR8fj4mJCajVakE9FXN1pKWl\nAQDu3r1r8rya4zQPoLKyMgBAbGyszW7Y2eL8+fMYHx8XbWjv6ekJjuMwPT2NDRs26P38xIkTOHHi\nBP8A1IzeOjo60NHRgebmZqPtxBwdummWPXv2YO/evdizZ49WmLvZS6iOyspKvtNTUVEh+NwbNmxA\nUlISb6ymcumWto/g4GCcPHkSnZ2dWnl8Q+kpUyNqS3S8++67gtJNKpUKKpUKCoXC5Aosse4XU2Yu\n1MhN6TAU9C4XgiAIe+Fl6aGnpKRoPdn37t1r8Dh/f3+t3V627KF3dHTwa9AHBweRl5eHvLw8BAYG\nIiUlBdPT07OmFizVcfHiRQBAeXm50WOioqLQ3NystUFF02Of7x46x3HYsWOHKOXh6OiIP//8E0ql\nUuv7Tk5OqKmp0euJjY+PY+PGjfxxRUVFmJiYMLjk0xwdHR0detcCDK9y6ejoMGuJqdAeuub85vTQ\nNREdHa2l0dA5LGkfly5dwvDwsNGesaaMZpZVT08Pdu/ejSVLlojSTkNDQ5Gbm8vHli1bsGbNGmRm\nZvKT1bm5uRgaGoJarUZycrKgjYHW3C+6aF4BYMk9JdhjXxZDZxgGPT09fIWPjY3h999/R319PbKz\ns5GdnY2rV69qpT44jsOpU6dErZCZhs6yLB4+fIivv/5aaynU0qVL0d/fD5ZlBU8MmatDs5FIJpPp\nbZ3evHkzNm/eDJZl8fz5c37CJyMjA2q1Go8fPza6dEuIDgcHByxatMiihufi4oLGxkY0NDSYvGHM\nLY/q6mo9Qy8qKtJbaXPq1Cl4e3trHdfb2wuOM/wqAnN0rFixAo2NjXxOdmJiAkqlkv//zO9z3ItV\nWEIms4XqmLnF3xJDZxhGa3LUUB7enPJwc3PDw4cPtVanVVVVobS0VOvVDJqyKC0thVqt1vr+48eP\n8fHHH1vdPoSGr68vnj59Co7j8OGHH4p+3+r8Lo+QiU9zdbz0hr5kyRKTOTBAuzc0PT2NlStX2qRC\nvvjiC6xfv97gzxITE3kDEbqEzlwdwcHB6O/vBwCo1Wrk5eVhzZo12Lp1K7+ZBwBKSkqwdu1a1NbW\n8sdGRkZapePQoUOzLm8zFpq16mJOijLMiwccy7Jaa9yfP38OjuPQ2NiIxsZGLFu2TO/38vPzwbIs\n6urqDD5grLlhjS1NDA0N5ZcTdnd3C3o4CtExW+9aSOjeU9aUh7+/v9a5bt68CQcHB3zwwQdanTOW\nZfnt9C4uLkhOTtYz9itXrsDX11eUepktGhoawHEcSkpKRKkXE7/73zZ0f39/fkebkLh//75NK8RY\nlJeXg2VZZGZmWlUhs/1OaGgoqqurMTk5CSF0dHSYNHOhOjQ9GGMrIYxFfn4+JicnMTQ0NOvmDnPL\nIyYmBmq1GmNjY0hNTQXDMPDy8kJFRQWSk5ORnJxsUI9mIlCMVS5Cw8/PT2tFjJCNLkJ01NbWmuxd\nC4mZPfR79+5ZVR4zDV0ulyM0NBShoaH8hiNNnDlzRu93vb29IZFIMDw8zPfwZ6YjLK0XR0dHeHt7\naz0cdOPTTz8Fx3GoqakRpV6Mhe6kqDVtSrDHimHUgi8mQHhkZCRKS0tx/PhxDA4OajUMmUwmaIuv\nrW5YHx8f+Pj44NGjR3P6LpfIyEhs27YNUqkUAPh0UFVVFUpKSnD48GHExsaKlhPUmJFMJhOkz8XF\nBV999RX//pKrV6/apDzu3LnDG1Jvby+/Bj4iIgIRERFwdXVFSEgIIiIiUFNTwxvXL7/8orfVXuz2\nERYWxq97f/bsmVa7XbdunSjlce7cOa3zCt1Gr4mZOyrFyKH7+vry70JRKBT80lnN6Lm5uRnNzc1G\n8+SaSEpKQltbG/8+IGvq5eTJkxgYGMDQ0JDBdJebmxsuXbo0J4auu4nI0NZ/obFgDX1meHt7Izg4\nmA8PDw9+uMRxHFpbW21aIbpRUlKCkpISsCyLnp4eoyZhKx3JyckAwO/IdHJyEqVh6B5z8OBB3jiL\ni4sNbsrw9fXll+k1NjbyvbT09HSTr821pjzCwsKQn59vdMQmlUr5jU+aFF1bW5teTl3Metm+fTtu\n3bplND3Y1NRkclu8OTo8PDz4TTQsy0IqlQp6JS7DvJgQ1aQ5NA86Q6+SMLc84uPj9d742Nraavay\nPLHqZeboQCaTobGxERkZGXxkZWXxHUUxDV0z4alr2IaWLopVHgvO0HUjKChIazb9yZMns/aSxdSh\n+UtBKpXK4BDf1jpWrFiB6elpDA8PY3h4WPCEm7k6nJycUFFRwZfz5OQkrl+/jp07d2LXrl346aef\nMDAwoHUT3759W5BxWVseTk5O2LBhA7q6ujA+Ps4bp24MDw8jNzd31oeeJTpcXV2xZcsWtLe3G324\njIyMQCKRCN5FKlSHbi9bLpcjMzPT6E5IT09PZGZm6j1ojD0MLCkPzaj67NmzWL16tUUdDbHaR2pq\nql7bNBS9vb0m0zLm6DD21kTdP15Bhq4Tixcv1uqBjY+Pz7pBQEwdmtdw/v3333PWQMUOoTqcnJxQ\nVlZm8v0tmgdLV1eX2TexteUREBCA1157DYWFhaiqqkJVVRU6OzuhUChQVVWFVatW2USH5v06hspD\ns3Hl/v37iI+Pt1l5FBYW6m3nHxsbg1QqhVQqRUFBAQoKCiCVSg1u/e/r6zPas19o7VQ33N3dUVBQ\noDfpqvtAEzr/Zamhm0Ks8jCoTQyjFnwxESo6Li4O5eXlmJ6exv79+23WMHRj//79fKMwtb7a1jrm\n+kZJTEzk//KMxsiUSiWOHj3K/xWeudDxspSHu7s7Ll++zKe9+vv7cffuXRw/fhwhISEW7RK1tDxu\n3bpl1LiMxf79+03W2UKtF92Ii4vDiRMnUF9frxUNDQ24cuWKqCMnYy/cMoYla9GFeqzDvwLnhH/f\n/zGnAHAQQ0dubi7z2WefMQzDMO+88w7T3d09LzqshXTYl47ly5czR44cYV5//XXmf//7HwOAefbs\nGcMwDNPT08P4+fkx7e3tTFlZGQOAKS8vt4kOsVmIOiQSCf/1jh07jJ7z7NmzzI0bN5gff/zRKh2G\nIEMXyA8//MC0t7czDMMwhw4dmjcd1kI6SAfpsA8dhnC2tRB74ZVXXmFKS0vnWwZBEIRRqIdOOkgH\n6SAdC1CHIebU0AmCIAjbQa/PJQiCsBPI0AmCIOwEMnSCIAg7gQydIAjCTiBDJwiCsBPI0AmCIOwE\nMnSCIAg7gQydIAjCTiBDJwiCsBPI0AmCIOwEMnSCIAg7gQydIAjCTiBDJwiCsBPI0AmCIOwEMnSC\nIAg7gQydIAjCTiBDJwiCsBPI0AmCIOwEMnSCIAg7gQydIAjCTiBDJwiCsBPI0AmCIOwEMnSCIAg7\n4f/YIfJ/6pzl6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1144b4610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-02-28 12:07:15.945052. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "np.random.seed(1234) # set seed for deterministic ordering\n",
    "p = np.random.permutation(mnist.data.shape[0])\n",
    "X = mnist.data[p]\n",
    "Y = mnist.target[p]\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.imshow(X[i].reshape((28,28)), cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "X = X.astype(np.float32)/255\n",
    "X_train = X[:60000]\n",
    "X_test = X[60000:]\n",
    "Y_train = Y[:60000]\n",
    "Y_test = Y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create data iterators from our MNIST data. A data iterator returns a batch of data examples each time for the network to process. MXNet provide a suite of basic DataIters for parsing different data format. Here we use NDArrayIter, which wraps around a numpy array and each time slice a chunk from it along the first dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-02-28 12:07:25.448982. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_iter = mx.io.NDArrayIter(X_train, Y_train, batch_size=batch_size,shuffle=True)\n",
    "test_iter = mx.io.NDArrayIter(X_test, Y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-02-28 12:07:26.153817. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "With the network and data source defined, we can finally start to train our model. We do this with MXNet's convenience wrapper for feed forward neural networks (it can also be made to handle RNNs with explicit unrolling). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Train-accuracy=0.743200\n",
      "INFO:root:Epoch[0] Time cost=0.763\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.953200\n",
      "INFO:root:Epoch[1] Train-accuracy=0.958733\n",
      "INFO:root:Epoch[1] Time cost=0.649\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.960200\n",
      "INFO:root:Epoch[2] Train-accuracy=0.971400\n",
      "INFO:root:Epoch[2] Time cost=0.645\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.965300\n",
      "INFO:root:Epoch[3] Train-accuracy=0.977833\n",
      "INFO:root:Epoch[3] Time cost=0.654\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.965400\n",
      "INFO:root:Epoch[4] Train-accuracy=0.981667\n",
      "INFO:root:Epoch[4] Time cost=0.644\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.974500\n",
      "INFO:root:Epoch[5] Train-accuracy=0.984383\n",
      "INFO:root:Epoch[5] Time cost=0.644\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.968400\n",
      "INFO:root:Epoch[6] Train-accuracy=0.985833\n",
      "INFO:root:Epoch[6] Time cost=0.642\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.971700\n",
      "INFO:root:Epoch[7] Train-accuracy=0.987867\n",
      "INFO:root:Epoch[7] Time cost=0.638\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.966000\n",
      "INFO:root:Epoch[8] Train-accuracy=0.988400\n",
      "INFO:root:Epoch[8] Time cost=0.639\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.974600\n",
      "INFO:root:Epoch[9] Train-accuracy=0.989517\n",
      "INFO:root:Epoch[9] Time cost=0.669\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.970400\n",
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-02-28 12:07:31.897208. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "model = mx.mod.Module(symbol=mlp, \n",
    "                    context=context,\n",
    "                    data_names=['data'], \n",
    "                    label_names=['softmax_label'])\n",
    "\n",
    "model.fit(train_iter, \n",
    "        eval_data=test_iter,\n",
    "        optimizer='sgd',\n",
    "        optimizer_params={'learning_rate':0.1,'momentum':0.9,'wd':0.00001},\n",
    "        eval_metric='acc',\n",
    "        num_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "After the model is trained, we can evaluate it on a held out test set.\n",
    "First, lets classity a sample image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b680610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Result: 7',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-02-28 12:07:46.283369. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "index_img = 0\n",
    "plt.imshow((X_test[index_img].reshape((28,28))*255).astype(np.uint8), cmap='Greys_r')\n",
    "plt.show()\n",
    "prediction_prob = model.predict(eval_data=test_iter,num_batch=1)\n",
    "clss_pred = prediction_prob[index_img].asnumpy()\n",
    "print('Result: {}'.format(clss_pred.argmax()),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate the model's accuracy on the entire test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accuracy', 0.96)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-02-28 12:07:50.451220. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "list(model.score(test_iter,eval_metric=['acc'],num_batch=1,)) #support for python 3 zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try if your model recognizes your own hand writing.\n",
    "\n",
    "Write a digit from 0 to 9 in the box below. Try to put your digit in the middle of the box.\n",
    "##### run hand drawing test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style type=\"text/css\">\n",
       "  canvas { border: 1px solid black; }\n",
       "</style>\n",
       "\n",
       "<div id=\"board\">\n",
       "\n",
       "  <canvas id=\"myCanvas\" width=\"100px\" height=\"100px\">\n",
       "    Sorry, your browser doesn't support canvas technology.\n",
       "  </canvas>\n",
       "\n",
       "  <p>\n",
       "\n",
       "    <button id=\"classify\" onclick=\"classify()\">\n",
       "      Classify\n",
       "    </button>\n",
       "\n",
       "    <button id=\"clear\" onclick=\"myClear()\">\n",
       "      Clear\n",
       "    </button>\n",
       "    Result: \n",
       "    <input type=\"text\" id=\"result_output\" size=\"5\" value=\"\">\n",
       "\n",
       "  </p>\n",
       "\n",
       "</div>\n",
       "\n",
       "<script type = \"text/JavaScript\" src = \"https://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js?ver=1.4.2\" > </script>\n",
       "\n",
       "<script type = \"text/javascript\" >\n",
       "\n",
       "    function init() {\n",
       "        var myCanvas = document.getElementById(\"myCanvas\");\n",
       "        var curColor = $('#selectColor option:selected').val();\n",
       "        if (myCanvas) {\n",
       "            var isDown = false;\n",
       "            var ctx = myCanvas.getContext(\"2d\");\n",
       "            var canvasX, canvasY;\n",
       "            ctx.lineWidth = 8;\n",
       "            $(myCanvas).mousedown(function(e) {\n",
       "                isDown = true;\n",
       "                ctx.beginPath();\n",
       "                var parentOffset = $(this).parent().offset();\n",
       "                canvasX = e.pageX - parentOffset.left;\n",
       "                canvasY = e.pageY - parentOffset.top;\n",
       "                ctx.moveTo(canvasX, canvasY);\n",
       "            }).mousemove(function(e) {\n",
       "                if (isDown != false) {\n",
       "                    var parentOffset = $(this).parent().offset();\n",
       "                    canvasX = e.pageX - parentOffset.left;\n",
       "                    canvasY = e.pageY - parentOffset.top;\n",
       "                    ctx.lineTo(canvasX, canvasY);\n",
       "                    ctx.strokeStyle = curColor;\n",
       "                    ctx.stroke();\n",
       "                }\n",
       "            }).mouseup(function(e) {\n",
       "                isDown = false;\n",
       "                ctx.closePath();\n",
       "            });\n",
       "        }\n",
       "        $('#selectColor').change(function() {\n",
       "            curColor = $('#selectColor option:selected').val();\n",
       "        });\n",
       "    }\n",
       "init();\n",
       "\n",
       "function handle_output(out) {\n",
       "    document.getElementById(\"result_output\").value = out.content.data[\"text/plain\"];\n",
       "}\n",
       "\n",
       "function classify() {\n",
       "    var kernel = IPython.notebook.kernel;\n",
       "    var myCanvas = document.getElementById(\"myCanvas\");\n",
       "    data = myCanvas.toDataURL('image/png');\n",
       "    document.getElementById(\"result_output\").value = \"\";\n",
       "    kernel.execute(\"classify('\" + data + \"')\", {\n",
       "        'iopub': {\n",
       "            'output': handle_output\n",
       "        }\n",
       "    }, {\n",
       "        silent: false\n",
       "    });\n",
       "}\n",
       "\n",
       "function myClear() {\n",
       "    var myCanvas = document.getElementById(\"myCanvas\");\n",
       "    myCanvas.getContext(\"2d\").clearRect(0, 0, myCanvas.width, myCanvas.height);\n",
       "}\n",
       "\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-02-28 12:07:56.089471. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(filename=\"../tutorials/mnist_demo.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-02-28 12:08:01.803722. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "def classify(img):\n",
    "    img = img[len('data:image/png;base64,'):].decode('base64')\n",
    "    img = np.fromstring(img, np.uint8)\n",
    "    img = skimage.transform.resize(img[:,:,3], (28,28))\n",
    "    img = img.astype(np.float32).reshape((1, 784))/255.0\n",
    "    return model.predict(img)[0].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging\n",
    "\n",
    "DNNs can perform poorly for a lot of reasons, like learning rate too big/small, initialization too big/small, network structure not reasonable, etc. When this happens it's often helpful to print out the weights and intermediate outputs to understand what's going on. MXNet provides a monitor utility that does this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Batch:       1 fc1_backward_weight            0.000579967\t\n",
      "INFO:root:Batch:       1 fc1_weight                     0.00577777\t\n",
      "INFO:root:Batch:       1 fc2_backward_weight            0.00191234\t\n",
      "INFO:root:Batch:       1 fc2_weight                     0.00577122\t\n",
      "INFO:root:Batch:       1 fc3_backward_weight            0.00597764\t\n",
      "INFO:root:Batch:       1 fc3_weight                     0.00581173\t\n",
      "INFO:root:Batch:     101 fc1_backward_weight            0.193102\t\n",
      "INFO:root:Batch:     101 fc1_weight                     0.00777461\t\n",
      "INFO:root:Batch:     101 fc2_backward_weight            0.423213\t\n",
      "INFO:root:Batch:     101 fc2_weight                     0.0189066\t\n",
      "INFO:root:Batch:     101 fc3_backward_weight            2.71352\t\n",
      "INFO:root:Batch:     101 fc3_weight                     0.0679579\t\n",
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 70049.13 samples/sec\tTrain-accuracy=0.138416\n",
      "INFO:root:Batch:     201 fc1_backward_weight            0.327856\t\n",
      "INFO:root:Batch:     201 fc1_weight                     0.0219581\t\n",
      "INFO:root:Batch:     201 fc2_backward_weight            0.863861\t\n",
      "INFO:root:Batch:     201 fc2_weight                     0.0470446\t\n",
      "INFO:root:Batch:     201 fc3_backward_weight            2.92742\t\n",
      "INFO:root:Batch:     201 fc3_weight                     0.223499\t\n",
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 56801.45 samples/sec\tTrain-accuracy=0.722100\n",
      "INFO:root:Batch:     301 fc1_backward_weight            0.213278\t\n",
      "INFO:root:Batch:     301 fc1_weight                     0.0290202\t\n",
      "INFO:root:Batch:     301 fc2_backward_weight            0.466087\t\n",
      "INFO:root:Batch:     301 fc2_weight                     0.0594957\t\n",
      "INFO:root:Batch:     301 fc3_backward_weight            1.15864\t\n",
      "INFO:root:Batch:     301 fc3_weight                     0.244294\t\n",
      "INFO:root:Epoch[0] Batch [300]\tSpeed: 57711.02 samples/sec\tTrain-accuracy=0.897500\n",
      "INFO:root:Batch:     401 fc1_backward_weight            0.131288\t\n",
      "INFO:root:Batch:     401 fc1_weight                     0.0341477\t\n",
      "INFO:root:Batch:     401 fc2_backward_weight            0.248494\t\n",
      "INFO:root:Batch:     401 fc2_weight                     0.0685767\t\n",
      "INFO:root:Batch:     401 fc3_backward_weight            0.746015\t\n",
      "INFO:root:Batch:     401 fc3_weight                     0.253705\t\n",
      "INFO:root:Epoch[0] Batch [400]\tSpeed: 58592.59 samples/sec\tTrain-accuracy=0.920700\n",
      "INFO:root:Batch:     501 fc1_backward_weight            0.162873\t\n",
      "INFO:root:Batch:     501 fc1_weight                     0.0379254\t\n",
      "INFO:root:Batch:     501 fc2_backward_weight            0.331654\t\n",
      "INFO:root:Batch:     501 fc2_weight                     0.0747298\t\n",
      "INFO:root:Batch:     501 fc3_backward_weight            0.781185\t\n",
      "INFO:root:Batch:     501 fc3_weight                     0.257357\t\n",
      "INFO:root:Epoch[0] Batch [500]\tSpeed: 56353.24 samples/sec\tTrain-accuracy=0.936600\n",
      "INFO:root:Epoch[0] Train-accuracy=0.942323\n",
      "INFO:root:Epoch[0] Time cost=1.032\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.942200\n",
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-02-28 12:08:39.340267. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "def norm_stat(d):\n",
    "    \"\"\"The statistics you want to see.\n",
    "    We compute the L2 norm here but you can change it to anything you like.\"\"\"\n",
    "    return mx.nd.norm(d)/np.sqrt(d.size)\n",
    "\n",
    "mon = mx.mon.Monitor(\n",
    "    100,                 # Print every 100 batches\n",
    "    norm_stat,           # The statistics function defined above\n",
    "    pattern='.*weight',  # A regular expression. Only arrays with name matching this pattern will be included.\n",
    "    sort=True)           # Sort output by name\n",
    "\n",
    "model = mx.mod.Module(symbol=mlp, \n",
    "                    context=context,\n",
    "                    data_names=['data'], \n",
    "                    label_names=['softmax_label'])\n",
    "\n",
    "model.fit(train_iter,\n",
    "        eval_data=test_iter,\n",
    "        optimizer='sgd',\n",
    "        optimizer_params={'learning_rate':0.1,'momentum':0.9,'wd':0.00001},\n",
    "        eval_metric='acc',monitor= mon,\n",
    "        num_epoch=1,batch_end_callback= mx.callback.Speedometer(100, 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under the hood: Custom Training Loop\n",
    "\n",
    "`mx.model.FeedForward` is a convenience wrapper for training standard feed forward networks. What if the model you are working with is more complicated? With MXNet, you can easily control every aspect of training by writing your own training loop.\n",
    "\n",
    "Neural network training typically has 3 steps: forward, backward (gradient), and update. With custom training loop, you can control the details in each step as while as insert complicated computations in between. You can also connect multiple networks together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input_shapes', {'softmax_label': (100,), 'data': (100, 784L)})\n",
      "('epoch:', 0, 'iter:', 100, 'metric:', ('accuracy', 0.1529))\n",
      "('epoch:', 0, 'iter:', 200, 'metric:', ('accuracy', 0.45285))\n",
      "('epoch:', 0, 'iter:', 300, 'metric:', ('accuracy', 0.6018))\n",
      "('epoch:', 0, 'iter:', 400, 'metric:', ('accuracy', 0.681925))\n",
      "('epoch:', 0, 'iter:', 500, 'metric:', ('accuracy', 0.7335))\n",
      "('epoch:', 0, 'iter:', 600, 'metric:', ('accuracy', 0.7691333333333333))\n",
      "('epoch:', 1, 'iter:', 100, 'metric:', ('accuracy', 0.9493))\n",
      "('epoch:', 1, 'iter:', 200, 'metric:', ('accuracy', 0.9528))\n",
      "('epoch:', 1, 'iter:', 300, 'metric:', ('accuracy', 0.9551333333333333))\n",
      "('epoch:', 1, 'iter:', 400, 'metric:', ('accuracy', 0.956325))\n",
      "('epoch:', 1, 'iter:', 500, 'metric:', ('accuracy', 0.95838))\n",
      "('epoch:', 1, 'iter:', 600, 'metric:', ('accuracy', 0.9594166666666667))\n",
      "('epoch:', 2, 'iter:', 100, 'metric:', ('accuracy', 0.9699))\n",
      "('epoch:', 2, 'iter:', 200, 'metric:', ('accuracy', 0.97015))\n",
      "('epoch:', 2, 'iter:', 300, 'metric:', ('accuracy', 0.9710666666666666))\n",
      "('epoch:', 2, 'iter:', 400, 'metric:', ('accuracy', 0.971325))\n",
      "('epoch:', 2, 'iter:', 500, 'metric:', ('accuracy', 0.97124))\n",
      "('epoch:', 2, 'iter:', 600, 'metric:', ('accuracy', 0.97175))\n",
      "('epoch:', 3, 'iter:', 100, 'metric:', ('accuracy', 0.9776))\n",
      "('epoch:', 3, 'iter:', 200, 'metric:', ('accuracy', 0.97645))\n",
      "('epoch:', 3, 'iter:', 300, 'metric:', ('accuracy', 0.9768666666666667))\n",
      "('epoch:', 3, 'iter:', 400, 'metric:', ('accuracy', 0.9773))\n",
      "('epoch:', 3, 'iter:', 500, 'metric:', ('accuracy', 0.97792))\n",
      "('epoch:', 3, 'iter:', 600, 'metric:', ('accuracy', 0.9784666666666667))\n",
      "('epoch:', 4, 'iter:', 100, 'metric:', ('accuracy', 0.9814))\n",
      "('epoch:', 4, 'iter:', 200, 'metric:', ('accuracy', 0.9811))\n",
      "('epoch:', 4, 'iter:', 300, 'metric:', ('accuracy', 0.9802333333333333))\n",
      "('epoch:', 4, 'iter:', 400, 'metric:', ('accuracy', 0.980425))\n",
      "('epoch:', 4, 'iter:', 500, 'metric:', ('accuracy', 0.98118))\n",
      "('epoch:', 4, 'iter:', 600, 'metric:', ('accuracy', 0.9811833333333333))\n",
      "('epoch:', 5, 'iter:', 100, 'metric:', ('accuracy', 0.9837))\n",
      "('epoch:', 5, 'iter:', 200, 'metric:', ('accuracy', 0.9832))\n",
      "('epoch:', 5, 'iter:', 300, 'metric:', ('accuracy', 0.9826666666666667))\n",
      "('epoch:', 5, 'iter:', 400, 'metric:', ('accuracy', 0.982525))\n",
      "('epoch:', 5, 'iter:', 500, 'metric:', ('accuracy', 0.9832))\n",
      "('epoch:', 5, 'iter:', 600, 'metric:', ('accuracy', 0.9836833333333334))\n",
      "('epoch:', 6, 'iter:', 100, 'metric:', ('accuracy', 0.9838))\n",
      "('epoch:', 6, 'iter:', 200, 'metric:', ('accuracy', 0.98515))\n",
      "('epoch:', 6, 'iter:', 300, 'metric:', ('accuracy', 0.9839666666666667))\n",
      "('epoch:', 6, 'iter:', 400, 'metric:', ('accuracy', 0.984425))\n",
      "('epoch:', 6, 'iter:', 500, 'metric:', ('accuracy', 0.98494))\n",
      "('epoch:', 6, 'iter:', 600, 'metric:', ('accuracy', 0.9855333333333334))\n",
      "('epoch:', 7, 'iter:', 100, 'metric:', ('accuracy', 0.9898))\n",
      "('epoch:', 7, 'iter:', 200, 'metric:', ('accuracy', 0.9893))\n",
      "('epoch:', 7, 'iter:', 300, 'metric:', ('accuracy', 0.9887666666666667))\n",
      "('epoch:', 7, 'iter:', 400, 'metric:', ('accuracy', 0.9886))\n",
      "('epoch:', 7, 'iter:', 500, 'metric:', ('accuracy', 0.98882))\n",
      "('epoch:', 7, 'iter:', 600, 'metric:', ('accuracy', 0.9888833333333333))\n",
      "('epoch:', 8, 'iter:', 100, 'metric:', ('accuracy', 0.9843))\n",
      "('epoch:', 8, 'iter:', 200, 'metric:', ('accuracy', 0.9863))\n",
      "('epoch:', 8, 'iter:', 300, 'metric:', ('accuracy', 0.9869))\n",
      "('epoch:', 8, 'iter:', 400, 'metric:', ('accuracy', 0.986975))\n",
      "('epoch:', 8, 'iter:', 500, 'metric:', ('accuracy', 0.98748))\n",
      "('epoch:', 8, 'iter:', 600, 'metric:', ('accuracy', 0.9878333333333333))\n",
      "('epoch:', 9, 'iter:', 100, 'metric:', ('accuracy', 0.992))\n",
      "('epoch:', 9, 'iter:', 200, 'metric:', ('accuracy', 0.9914))\n",
      "('epoch:', 9, 'iter:', 300, 'metric:', ('accuracy', 0.9907333333333334))\n",
      "('epoch:', 9, 'iter:', 400, 'metric:', ('accuracy', 0.9907))\n",
      "('epoch:', 9, 'iter:', 500, 'metric:', ('accuracy', 0.9907))\n",
      "('epoch:', 9, 'iter:', 600, 'metric:', ('accuracy', 0.9902333333333333))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-02-28 12:08:46.403219. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# ==================Binding=====================\n",
    "# The symbol we created is only a graph description.\n",
    "# To run it, we first need to allocate memory and create an executor by 'binding' it.\n",
    "# In order to bind a symbol, we need at least two pieces of information: context and input shapes.\n",
    "# Context specifies which device the executor runs on, e.g. cpu, GPU0, GPU1, etc.\n",
    "# Input shapes define the executor's input array dimensions.\n",
    "# MXNet then run automatic shape inference to determine the dimensions of intermediate and output arrays.\n",
    "\n",
    "# data iterators defines shapes of its output with provide_data and provide_label property.\n",
    "input_shapes = dict(train_iter.provide_data+train_iter.provide_label)\n",
    "print ('input_shapes', input_shapes)\n",
    "# We use simple_bind to let MXNet allocate memory for us.\n",
    "# You can also allocate memory youself and use bind to pass it to MXNet.\n",
    "exe = mlp.simple_bind(ctx=context, **input_shapes)\n",
    "\n",
    "# ===============Initialization=================\n",
    "# First we get handle to input arrays\n",
    "arg_arrays = dict(zip(mlp.list_arguments(), exe.arg_arrays))\n",
    "data = arg_arrays[train_iter.provide_data[0][0]]\n",
    "label = arg_arrays[train_iter.provide_label[0][0]]\n",
    "\n",
    "# We initialize the weights with uniform distribution on (-0.01, 0.01).\n",
    "init = mx.init.Uniform(scale=0.01)\n",
    "for name, arr in arg_arrays.items():\n",
    "    if name not in input_shapes:\n",
    "        init(mx.init.InitDesc(name), arr)\n",
    "    \n",
    "# We also need to create an optimizer for updating weights\n",
    "opt = mx.optimizer.SGD(\n",
    "    learning_rate=0.1,\n",
    "    momentum=0.9,\n",
    "    wd=0.00001,\n",
    "    rescale_grad=1.0/train_iter.batch_size)\n",
    "updater = mx.optimizer.get_updater(opt)\n",
    "\n",
    "# Finally we need a metric to print out training progress\n",
    "metric = mx.metric.Accuracy()\n",
    "\n",
    "# Training loop begines\n",
    "for epoch in range(10):\n",
    "    train_iter.reset()\n",
    "    metric.reset()\n",
    "    t = 0\n",
    "    for batch in train_iter:\n",
    "        # Copy data to executor input. Note the [:].\n",
    "        data[:] = batch.data[0]\n",
    "        label[:] = batch.label[0]\n",
    "        \n",
    "        # Forward\n",
    "        exe.forward(is_train=True)\n",
    "        \n",
    "        # You perform operations on exe.outputs here if you need to.\n",
    "        # For example, you can stack a CRF on top of a neural network.\n",
    "        \n",
    "        # Backward\n",
    "        exe.backward()\n",
    "        \n",
    "        # Update\n",
    "        for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):\n",
    "            weight, grad = pair\n",
    "            updater(i, grad, weight)\n",
    "        metric.update(batch.label, exe.outputs)\n",
    "        t += 1\n",
    "        if t % 100 == 0:\n",
    "            print ('epoch:', epoch, 'iter:', t, 'metric:', metric.get())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Operators\n",
    "\n",
    "MXNet provides a repository of common operators (or layers). However, new models often require new layers. There are several ways to [create new operators](https://mxnet.readthedocs.org/en/latest/tutorial/new_op_howto.html) with MXNet. Here we talk about the easiest way: pure python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Train-accuracy=nan\n",
      "INFO:root:Epoch[0] Time cost=0.001\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.128000\n",
      "INFO:root:Batch:     601 fc1_backward_weight            0.000573766\t\n",
      "INFO:root:Batch:     601 fc1_weight                     0.0410163\t\n",
      "INFO:root:Batch:     601 fc1_weight                     0.00578439\t\n",
      "INFO:root:Batch:     601 fc2_backward_weight            0.00197665\t\n",
      "INFO:root:Batch:     601 fc2_weight                     0.0817942\t\n",
      "INFO:root:Batch:     601 fc2_weight                     0.00573697\t\n",
      "INFO:root:Batch:     601 fc3_backward_weight            0.00617059\t\n",
      "INFO:root:Batch:     601 fc3_weight                     0.262115\t\n",
      "INFO:root:Batch:     601 fc3_weight                     0.00586618\t\n",
      "INFO:root:Batch:     701 fc1_backward_weight            0.205179\t\n",
      "INFO:root:Batch:     701 fc1_weight                     0.0410163\t\n",
      "INFO:root:Batch:     701 fc1_weight                     0.00921468\t\n",
      "INFO:root:Batch:     701 fc2_backward_weight            0.618877\t\n",
      "INFO:root:Batch:     701 fc2_weight                     0.0817942\t\n",
      "INFO:root:Batch:     701 fc2_weight                     0.0244061\t\n",
      "INFO:root:Batch:     701 fc3_backward_weight            4.54543\t\n",
      "INFO:root:Batch:     701 fc3_weight                     0.262115\t\n",
      "INFO:root:Batch:     701 fc3_weight                     0.0965187\t\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 35865.92 samples/sec\tTrain-accuracy=0.158119\n",
      "INFO:root:Batch:     801 fc1_backward_weight            0.235525\t\n",
      "INFO:root:Batch:     801 fc1_weight                     0.0410163\t\n",
      "INFO:root:Batch:     801 fc1_weight                     0.0234647\t\n",
      "INFO:root:Batch:     801 fc2_backward_weight            0.521232\t\n",
      "INFO:root:Batch:     801 fc2_weight                     0.0817942\t\n",
      "INFO:root:Batch:     801 fc2_weight                     0.0492508\t\n",
      "INFO:root:Batch:     801 fc3_backward_weight            1.39495\t\n",
      "INFO:root:Batch:     801 fc3_weight                     0.262115\t\n",
      "INFO:root:Batch:     801 fc3_weight                     0.214029\t\n",
      "INFO:root:Epoch[1] Batch [200]\tSpeed: 41719.34 samples/sec\tTrain-accuracy=0.739800\n",
      "INFO:root:Batch:     901 fc1_backward_weight            0.103812\t\n",
      "INFO:root:Batch:     901 fc1_weight                     0.0410163\t\n",
      "INFO:root:Batch:     901 fc1_weight                     0.0304797\t\n",
      "INFO:root:Batch:     901 fc2_backward_weight            0.266583\t\n",
      "INFO:root:Batch:     901 fc2_weight                     0.0817942\t\n",
      "INFO:root:Batch:     901 fc2_weight                     0.0619285\t\n",
      "INFO:root:Batch:     901 fc3_backward_weight            0.667005\t\n",
      "INFO:root:Batch:     901 fc3_weight                     0.262115\t\n",
      "INFO:root:Batch:     901 fc3_weight                     0.232072\t\n",
      "INFO:root:Epoch[1] Batch [300]\tSpeed: 41212.14 samples/sec\tTrain-accuracy=0.894700\n",
      "INFO:root:Batch:    1001 fc1_backward_weight            0.142405\t\n",
      "INFO:root:Batch:    1001 fc1_weight                     0.0410163\t\n",
      "INFO:root:Batch:    1001 fc1_weight                     0.0353\t\n",
      "INFO:root:Batch:    1001 fc2_backward_weight            0.317499\t\n",
      "INFO:root:Batch:    1001 fc2_weight                     0.0817942\t\n",
      "INFO:root:Batch:    1001 fc2_weight                     0.0703766\t\n",
      "INFO:root:Batch:    1001 fc3_backward_weight            0.699576\t\n",
      "INFO:root:Batch:    1001 fc3_weight                     0.262115\t\n",
      "INFO:root:Batch:    1001 fc3_weight                     0.241625\t\n",
      "INFO:root:Epoch[1] Batch [400]\tSpeed: 45648.76 samples/sec\tTrain-accuracy=0.924500\n",
      "INFO:root:Batch:    1101 fc1_backward_weight            0.170826\t\n",
      "INFO:root:Batch:    1101 fc1_weight                     0.0410163\t\n",
      "INFO:root:Batch:    1101 fc1_weight                     0.0391072\t\n",
      "INFO:root:Batch:    1101 fc2_backward_weight            0.387486\t\n",
      "INFO:root:Batch:    1101 fc2_weight                     0.0817942\t\n",
      "INFO:root:Batch:    1101 fc2_weight                     0.0776397\t\n",
      "INFO:root:Batch:    1101 fc3_backward_weight            0.962787\t\n",
      "INFO:root:Batch:    1101 fc3_weight                     0.262115\t\n",
      "INFO:root:Batch:    1101 fc3_weight                     0.249665\t\n",
      "INFO:root:Epoch[1] Batch [500]\tSpeed: 65939.57 samples/sec\tTrain-accuracy=0.934400\n",
      "INFO:root:Epoch[1] Train-accuracy=0.948586\n",
      "INFO:root:Epoch[1] Time cost=1.359\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.952300\n"
     ]
    }
   ],
   "source": [
    "# Define custom softmax operator\n",
    "class NumpySoftmax(mx.operator.NumpyOp):\n",
    "    def __init__(self):\n",
    "        # Call the parent class constructor. \n",
    "        # Because NumpySoftmax is a loss layer, it doesn't need gradient input from layers above.\n",
    "        super(NumpySoftmax, self).__init__(need_top_grad=False)\n",
    "    \n",
    "    def list_arguments(self):\n",
    "        # Define the input to NumpySoftmax.\n",
    "        return ['data', 'label']\n",
    "\n",
    "    def list_outputs(self):\n",
    "        # Define the output.\n",
    "        return ['output']\n",
    "\n",
    "    def infer_shape(self, in_shape):\n",
    "        # Calculate the dimensions of the output (and missing inputs) from (some) input shapes.\n",
    "        data_shape = in_shape[0]  # shape of first argument 'data'\n",
    "        label_shape = (in_shape[0][0],)  # 'label' should be one dimensional and has batch_size instances.\n",
    "        output_shape = in_shape[0] # 'output' dimension is the same as the input.\n",
    "        return [data_shape, label_shape], [output_shape]\n",
    "\n",
    "    def forward(self, in_data, out_data):\n",
    "        x = in_data[0]  # 'data'\n",
    "        y = out_data[0]  # 'output'\n",
    "        \n",
    "        # Compute softmax\n",
    "        y[:] = np.exp(x - x.max(axis=1).reshape((x.shape[0], 1)))\n",
    "        y /= y.sum(axis=1).reshape((x.shape[0], 1))\n",
    "\n",
    "    def backward(self, out_grad, in_data, out_data, in_grad):\n",
    "        l = in_data[1]  # 'label'\n",
    "        l = l.reshape((l.size,)).astype(np.int)  # cast to int\n",
    "        y = out_data[0]  # 'output'\n",
    "        dx = in_grad[0]  # gradient for 'data'\n",
    "        \n",
    "        # Compute gradient\n",
    "        dx[:] = y\n",
    "        dx[np.arange(l.shape[0]), l] -= 1.0\n",
    "\n",
    "numpy_softmax = NumpySoftmax()\n",
    "\n",
    "data = mx.symbol.Variable('data')\n",
    "fc1 = mx.symbol.FullyConnected(data = data, name='fc1', num_hidden=128)\n",
    "act1 = mx.symbol.Activation(data = fc1, name='relu1', act_type=\"relu\")\n",
    "fc2 = mx.symbol.FullyConnected(data = act1, name = 'fc2', num_hidden = 64)\n",
    "act2 = mx.symbol.Activation(data = fc2, name='relu2', act_type=\"relu\")\n",
    "fc3 = mx.symbol.FullyConnected(data = act2, name='fc3', num_hidden=10)\n",
    "# Use the new operator we just defined instead of the standard softmax operator.\n",
    "mlp = numpy_softmax(data=fc3, name = 'softmax')\n",
    "\n",
    "model = mx.mod.Module(symbol=mlp, \n",
    "                    context=context,\n",
    "                    data_names=['data'], \n",
    "                    label_names=['softmax_label'])\n",
    "\n",
    "model.fit(train_iter,\n",
    "        eval_data=test_iter,\n",
    "        optimizer='sgd',\n",
    "        optimizer_params={'learning_rate':0.1,'momentum':0.9,'wd':0.00001},\n",
    "        eval_metric='acc',monitor= mon,\n",
    "        num_epoch=2,batch_end_callback= mx.callback.Speedometer(100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Readings\n",
    "\n",
    "- More state-of-the-art cnn models are available at [mxnet/example/image-classification](https://github.com/dmlc/mxnet/tree/master/example/image-classification)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
