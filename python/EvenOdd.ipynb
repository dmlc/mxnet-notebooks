{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Loss\n",
    "The most basic use case for MNIST is to train a model that classifies digits. This tutorial shows how to train a model that can classify digits as well as distinguish between even and odd numbers.\n",
    "\n",
    "## Prepare data\n",
    "First we download the dataset and obtain data iterators for MNIST training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import mxnet as mx\n",
    "import mxnet.metric\n",
    "import numpy as np\n",
    "mxnet_path = os.path.dirname(os.path.abspath(os.path.expanduser(mxnet.__file__)))\n",
    "sys.path.append(os.path.join(mxnet_path, \"../../tests/python/common\"))\n",
    "sys.path.append(os.path.join(mxnet_path, \"../../example/python-howto\"))\n",
    "from data import mnist_iterator\n",
    "train, val = mnist_iterator(batch_size=100, input_shape = (784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data iterator\n",
    "\n",
    "Now we will create a new iterator that will allow us to multitask, classifying digits *and* parity. We can build off of the MNIST iterator, which returns batches of input data and labels for digits 0, 1,...,9. We need this iterator to return batches of data with both labels for digits 0, 1,...,9 as well as labels for even and odd. To create this second set of labels, we simply calculate the parity based off of the ground truth we already have - the digit labels.\n",
    "\n",
    "* For **provide_data()** we are going to return MNIST iterator's data description since we want to keep the input data format the same.\n",
    "* For **provide_label()** we are returning a list of 2 data descriptions: the first item is the name and shape of the digit labels, the second item is the name and shape of the parity labels.\n",
    "* For **next()** we are returning a DataBatch object whose data field is set to the batch input, and the label field is set to a list of 2 lists: one with labels for the digit and the other with labels for the parity.\n",
    "\n",
    "[Read more about the DataIter API.](http://mxnet.io/api/python/io.html?highlight=dataiter#mxnet.io.DataIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EvenOdd_iterator(mx.io.DataIter):\n",
    "    '''multi label ilab iterator'''\n",
    "\n",
    "    def __init__(self, data_iter):\n",
    "        super(EvenOdd_iterator, self).__init__()\n",
    "        self.data_iter = data_iter\n",
    "        self.batch_size = self.data_iter.batch_size\n",
    "\n",
    "    @property\n",
    "    def provide_data(self):\n",
    "        return self.data_iter.provide_data\n",
    "\n",
    "    @property\n",
    "    def provide_label(self):\n",
    "        return [mx.io.DataDesc('softmaxdigit_label', (self.batch_size,), np.float32),\n",
    "                mx.io.DataDesc('softmaxeo_label', (self.batch_size,), np.float32)]\n",
    "\n",
    "    def hard_reset(self):\n",
    "        self.data_iter.hard_reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.data_iter.reset()\n",
    "\n",
    "    def next(self):\n",
    "        batch = self.data_iter.next()\n",
    "        labels = []\n",
    "        labels.append(batch.label[0]) \n",
    "        eolabels = []\n",
    "        for i in batch.label[0].asnumpy():\n",
    "            eolabels.append(i%2)\n",
    "        eolabels = mx.nd.array(np.array(eolabels))\n",
    "        labels.append(eolabels)\n",
    "        return mx.io.DataBatch(data=batch.data, label=labels, pad=batch.pad, index=batch.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just pass the MNIST iterators to iterator we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_train = EvenOdd_iterator(train)\n",
    "_val = EvenOdd_iterator(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We create a class to help evaluate how accurately the model is classifying digits *and* parity. We know that for each example, the model will make 2 predictions (one for each of the above). So for a batch of n examples, the model makes 2n predictions. We want to keep track of how many of the 2n predictions were correct. \n",
    "\n",
    "Our class can extend the mx.metric.EvalMetric class. We will set **num_inst** to 2n and increment **sum_metric** every time the model predicted correctly. Then, EvalMetric can use those to numbers to return an evaluation number.\n",
    "\n",
    "[Read more about EvalMetric API](http://mxnet.io/api/python/model.html?highlight=evalmetric#mxnet.metric.EvalMetric)\n",
    "\n",
    "To show the status of training, we will also write a function to be called after every epoch. What would be helpful in those status reports is a simple visualization of how many correct and incorrect predictions there are for each label. Take parity for example:\n",
    "\n",
    "[[90  10]\n",
    " [ 20 80]]\n",
    " \n",
    "The first row tells us that the model correctly labeled even examples 90 times, and incorrectly labeled even examples as odd 10 times. The second row tells us that the model correctly labeled odd examples 80 times, and incorrectly labeled even examples as odd 20 times. What we want to see are big numbers on the main diagonal.\n",
    "\n",
    "So, we will also build this state into the evaluation class and have the status function print this state out after every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MNISTPerDigitAccuracy(mx.metric.EvalMetric):\n",
    "    \"\"\"Calculate accuracy\"\"\"\n",
    "\n",
    "    def reset(self):\n",
    "        if hasattr(self, 'cms'):\n",
    "            for cm in self.cms:\n",
    "                cm.fill(0)\n",
    "        \n",
    "\n",
    "    def __init__(self,sizes):\n",
    "        super(MNISTPerDigitAccuracy, self).__init__('mnistperdigiaccuracy')\n",
    "        self.cms = map( lambda x: np.zeros((x,x), dtype=int), sizes )\n",
    "        self.reset()\n",
    "        self.thing = 0\n",
    "        return super(MNISTPerDigitAccuracy, self).reset()\n",
    "\n",
    "    def update(self, labels, preds):\n",
    "        mx.metric.check_label_shapes(labels, preds)\n",
    "        for i in range(len(labels)):\n",
    "            for label, pred_label in zip(labels[i].asnumpy(), preds[i].asnumpy()):\n",
    "                pred_label = int(np.argmax(pred_label))\n",
    "                label = int(label)\n",
    "                self.cms[i][label,pred_label] += 1\n",
    "                self.sum_metric += (pred_label == label)\n",
    "                self.num_inst += 1\n",
    "                \n",
    "def perDigitMetric(params):\n",
    "    for i, cm in enumerate(params.eval_metric.cms):\n",
    "        print \"Label=\", i\n",
    "        print cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Now we build the model. It will be similar to the one we build for digit classification, except we add another layer, fc3eo, to predict the parity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = mx.symbol.Variable('data')\n",
    "fc1 = mx.symbol.FullyConnected(data = data, name='fc1', num_hidden=128)\n",
    "act1 = mx.symbol.Activation(data = fc1, name='relu1', act_type=\"relu\")\n",
    "fc2 = mx.symbol.FullyConnected(data = act1, name = 'fc2', num_hidden = 64)\n",
    "act2 = mx.symbol.Activation(data = fc2, name='relu2', act_type=\"relu\")\n",
    "fc3digit = mx.symbol.FullyConnected(data = act2, name='fc3', num_hidden=10)\n",
    "fc3eo = mx.symbol.FullyConnected(data = act2, name='fc3eo', num_hidden=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the output symbols. We will group those two symbols together so we can multitask our learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp1 = mx.symbol.SoftmaxOutput(data = fc3digit, name = 'softmaxdigit')\n",
    "mlp2 = mx.symbol.SoftmaxOutput(data = fc3eo, name = 'softmaxeo')\n",
    "mlp = mx.symbol.Group([mlp1,mlp2])\n",
    "\n",
    "optimizer_params = (('learning_rate', 0.1),('momentum', 0.9), ('wd', 0.00001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Now let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 31839.65 samples/sec\tTrain-mnistperdigiaccuracy=0.403762\n",
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 35066.44 samples/sec\tTrain-mnistperdigiaccuracy=0.605572\n",
      "INFO:root:Epoch[0] Batch [300]\tSpeed: 27333.91 samples/sec\tTrain-mnistperdigiaccuracy=0.712475\n",
      "INFO:root:Epoch[0] Batch [400]\tSpeed: 27062.64 samples/sec\tTrain-mnistperdigiaccuracy=0.769825\n",
      "INFO:root:Epoch[0] Batch [500]\tSpeed: 33326.43 samples/sec\tTrain-mnistperdigiaccuracy=0.807036\n",
      "INFO:root:Epoch[0] Train-mnistperdigiaccuracy=0.831658\n",
      "INFO:root:Epoch[0] Time cost=1.945\n",
      "INFO:root:Epoch[0] Validation-mnistperdigiaccuracy=0.850236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label= 0\n",
      "[[ 959    0    2    2    0    3    8    5    1    0]\n",
      " [   0 1118    5    2    0    1    4    1    4    0]\n",
      " [   9    0  996    7    4    1    2    8    5    0]\n",
      " [   0    0   10  974    0    2    0   11    4    9]\n",
      " [   1    0    3    0  918    0   14    2    3   41]\n",
      " [   3    1    1   34    1  819   10    9    5    9]\n",
      " [  10    3    3    1    5    8  925    0    3    0]\n",
      " [   1    8   16    4    1    0    0  971    0   27]\n",
      " [   9    2   11   19    6   15   24    8  869   11]\n",
      " [   4    5    0   10   17    8    0    6    0  959]]\n",
      "Label= 1\n",
      "[[4728  198]\n",
      " [  76 4998]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 29954.20 samples/sec\tTrain-mnistperdigiaccuracy=0.864182\n",
      "INFO:root:Epoch[1] Batch [200]\tSpeed: 35452.56 samples/sec\tTrain-mnistperdigiaccuracy=0.875816\n",
      "INFO:root:Epoch[1] Batch [300]\tSpeed: 35527.01 samples/sec\tTrain-mnistperdigiaccuracy=0.885080\n",
      "INFO:root:Epoch[1] Batch [400]\tSpeed: 27720.73 samples/sec\tTrain-mnistperdigiaccuracy=0.892893\n",
      "INFO:root:Epoch[1] Batch [500]\tSpeed: 31716.02 samples/sec\tTrain-mnistperdigiaccuracy=0.899563\n",
      "INFO:root:Epoch[1] Train-mnistperdigiaccuracy=0.905000\n",
      "INFO:root:Epoch[1] Time cost=1.858\n",
      "INFO:root:Epoch[1] Validation-mnistperdigiaccuracy=0.909675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label= 0\n",
      "[[ 966    0    0    0    0    2    9    1    2    0]\n",
      " [   0 1121    3    2    0    1    2    3    3    0]\n",
      " [  12    0  995    4    2    2    1    7    7    2]\n",
      " [   0    0    5  934    0   54    0    4    7    6]\n",
      " [   2    0    1    0  952    0   14    2    1   10]\n",
      " [   3    1    1    1    3  866    8    2    3    4]\n",
      " [   6    2    1    0    4    5  938    0    2    0]\n",
      " [   1    5    9    5    4    0    0  969    3   32]\n",
      " [  15    0    9    7   10   16   25    3  879   10]\n",
      " [   4    2    0    7   32   10    0    3    2  949]]\n",
      "Label= 1\n",
      "[[4852   74]\n",
      " [  86 4988]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 34112.68 samples/sec\tTrain-mnistperdigiaccuracy=0.913931\n",
      "INFO:root:Epoch[2] Batch [200]\tSpeed: 32506.58 samples/sec\tTrain-mnistperdigiaccuracy=0.917936\n",
      "INFO:root:Epoch[2] Batch [300]\tSpeed: 33970.97 samples/sec\tTrain-mnistperdigiaccuracy=0.921379\n",
      "INFO:root:Epoch[2] Batch [400]\tSpeed: 34072.36 samples/sec\tTrain-mnistperdigiaccuracy=0.924339\n",
      "INFO:root:Epoch[2] Batch [500]\tSpeed: 33754.04 samples/sec\tTrain-mnistperdigiaccuracy=0.927194\n",
      "INFO:root:Epoch[2] Train-mnistperdigiaccuracy=0.929848\n",
      "INFO:root:Epoch[2] Time cost=1.775\n",
      "INFO:root:Epoch[2] Validation-mnistperdigiaccuracy=0.931976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label= 0\n",
      "[[ 974    1    2    1    0    0    0    0    1    1]\n",
      " [   0 1125    3    0    0    0    3    0    4    0]\n",
      " [   6    1 1009    2    1    0    0    4    9    0]\n",
      " [   1    2   14  954    0   17    0    4   11    7]\n",
      " [   2    0    2    0  947    0    5    2    0   24]\n",
      " [   8    0    1    3    0  847   13    7    4    9]\n",
      " [  12    2   12    0    3    4  921    1    3    0]\n",
      " [   2    4   11    3    1    0    0  966    4   37]\n",
      " [   9    1   10    5    4    4    7    2  928    4]\n",
      " [   2    2    1    4    7    6    1    1    3  982]]\n",
      "Label= 1\n",
      "[[4870   56]\n",
      " [ 106 4968]]\n"
     ]
    }
   ],
   "source": [
    "mod = mx.mod.Module(mlp,label_names=['softmaxdigit_label','softmaxeo_label'])\n",
    "mod.fit(_train, \n",
    "        eval_data=_val,\n",
    "        optimizer_params=optimizer_params,\n",
    "        eval_metric=MNISTPerDigitAccuracy([10,2]),\n",
    "        eval_end_callback=perDigitMetric,\n",
    "        num_epoch=3, batch_end_callback=mx.callback.Speedometer(100,100))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
