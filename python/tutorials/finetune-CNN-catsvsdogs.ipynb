{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Fine-tuning a CNN with MXNet: Cats vs Dogs (Kaggle Redux)\n",
    "\n",
    "In this tutorial we'll learn how to build a model to classifiy if an image is a cat or a dog. We'll use a pre-trained [imagenet](http://www.image-net.org/) model from the MXNet [model zoo](http://data.mxnet.io/models/). For practical problems we may not have a large dataset, hence its difficult to train these generalized models. However we can take advantage of models that are pre-trained on large dataset like imagenet where in the model has already learnt a lot of the image features. \n",
    "\n",
    "The model used is based on the Convolution Neural Network (CNN) architecture. CNN's consist of multiple layer of fields that are model on biological visual receptors. At each layer the neuron collection process portions of input images and the outputs get tiled so as to obtain a higher level representation of the image. For more details on the how CNN's work check out [CS231n course](http://cs231n.github.io/convolutional-networks/#overview) and [MNIST example](https://github.com/dmlc/mxnet-notebooks/blob/master/python/tutorials/mnist.ipynb) with MXNet.\n",
    "\n",
    "To fine-tune a network we'll update all of the network’s weights and also replace the last fully-connected layer with the new number of output classes. In most cases to train we use a smaller learning rate given that we typically may have a small dataset. For more in depth reading on fine-tuning with MXNet check this [tutorial](http://mxnet.io/how_to/finetune.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setting up a deep learning environment with AWS Deep Learning AMI for MXNet\n",
    "\n",
    "In this tutorial, we are going to use [Deep Learning AMI](https://aws.amazon.com/marketplace/pp/B06VSPXKDX). The Deep Learning AMI is a base Amazon Linux image provided by Amazon Web Services for use on Amazon Elastic Compute Cloud (Amazon EC2).It is designed to provide a stable, secure, and high performance execution environment for deep learning applications running on Amazon EC2. It includes popular deep learning frameworks, including MXNet.\n",
    "\n",
    "For setting up an Deep Learning environment on AWS using Deep Learning AMI, please read [this post on AWS AI Blog](https://aws.amazon.com/blogs/ai/the-aws-deep-learning-ami-now-with-ubuntu/) for detailed instruction. \n",
    "\n",
    "Or you can choose to [install MXNet](http://mxnet.io/get_started/install.html) to your own machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Prerequisites\n",
    "\n",
    " - MXNet (0.9.3 or higher)\n",
    " - Python 2.7 or higher\n",
    " - im2rec.py (clone https://github.com/dmlc/mxnet) \n",
    " - [recommended] Amazon EC2 instance with GPU (p2.* family) with [Deep Learning AMI](https://bit.ly/deepami)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Dataset: downoad and preprocessing\n",
    "\n",
    "1. Download data from https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data\n",
    "\n",
    "2. Extract train.zip into a folder \"data\" and create two folders \"train\" and \"valid\"\n",
    "\n",
    "3. Create additonal directories to get a directory structure as shown below, We'll label dogs as class 0 and cats as 1 (hence the prefix)\n",
    "\n",
    "```\n",
    "    train/\n",
    "\n",
    "    ├── 1cats\n",
    "    └── 0dogs\n",
    "\n",
    "    valid/\n",
    "\n",
    "    ├── 1cats\n",
    "    └── 0dogs\n",
    "```\n",
    "\n",
    "4. First move all the cat* images into train/1cats and dog* images into train/0dogs. \n",
    "\n",
    "5. Now lets move a percentage of these images in to the validation directory to create the validation set. You could use the code below to execute in a python script\n",
    "\n",
    "```\n",
    "    import os\n",
    "    import random\n",
    "    import shutil\n",
    "\n",
    "    cats_dir = 'train/1cats'\n",
    "    dogs_dir = 'train/0dogs'\n",
    "\n",
    "    all_cats = os.listdir(cats_dir)\n",
    "    all_dogs = os.listdir(dogs_dir)\n",
    "    p = 20.0\n",
    "    N = int(len(all_cats)/p)\n",
    "    N = int(len(all_dogs)/p)\n",
    "\n",
    "    for f in random.sample(all_cats, N):\n",
    "       shutil.move( cats_dir + \"/\" + f, \"valid/1cats/\" + f)\n",
    "\n",
    "    for f in random.sample(all_dogs, N):\n",
    "        shutil.move( dogs_dir + \"/\" + f, \"valid/0dogs/\" + f)\n",
    "```\n",
    "\n",
    "6. Create a list for training and validation set\n",
    "```\n",
    " python ~/mxnet/tools/im2rec.py --list True --recursive True cats_dogs_train.lst data/train\n",
    "\n",
    " python ~/mxnet/tools/im2rec.py --list True --recursive True cats_dogs_val.lst data/valid\n",
    "```\n",
    "\n",
    "7. Convert the images in to MXNet RecordIO format\n",
    "```\n",
    " python ~/mxnet/tools/im2rec.py --resize 224 --quality 90 --num-thread 16 cats_dogs_train.lst data/train\n",
    "\n",
    " python ~/mxnet/tools/im2rec.py --resize 224 --quality 90 --num-thread 16 cats_dogs_val.lst data/valid\n",
    "```    \n",
    "You should see cats_dogs_train.rec and cats_dogs_val.rec files created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next we define the function which returns the data iterators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data Iterators for cats vs dogs dataset\n",
    "\n",
    "import mxnet as mx\n",
    "\n",
    "def get_iterators(batch_size, data_shape=(3, 224, 224)):\n",
    "    train = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = './cats_dogs_train.rec', \n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        shuffle             = True,\n",
    "        rand_crop           = True,\n",
    "        rand_mirror         = True)\n",
    "    val = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = './cats_dogs_val.rec',\n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        rand_crop           = False,\n",
    "        rand_mirror         = False)\n",
    "    return (train, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dowload pre-trained model from the model zoo (Resnet-152)\n",
    "\n",
    "We then download a pretrained 152-layer ResNet model and load into memory.\n",
    "\n",
    "    Note: If load_checkpoint reports error, we can remove the downloaded files and try get_model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "import os, urllib\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.urlretrieve(url, filename)\n",
    "        \n",
    "def get_model(prefix, epoch):\n",
    "    download(prefix+'-symbol.json')\n",
    "    download(prefix+'-%04d.params' % (epoch,))\n",
    "\n",
    "get_model('http://data.mxnet.io/models/imagenet/resnet/152-layers/resnet-152', 0)\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-152', 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fine tuning the model\n",
    "\n",
    "\n",
    "To fine-tune a network, we must first replace the last fully-connected layer with a new one that outputs the desired number of classes. We initialize its weights randomly. Then we continue training as normal. Sometimes it’s common use a smaller learning rate based on the intuition that we may already be close to a good result.\n",
    "\n",
    "We first define a function which replaces the the last fully-connected layer for a given network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_fine_tune_model(symbol, arg_params, num_classes, layer_name='flatten0'):\n",
    "    \"\"\"\n",
    "    symbol: the pre-trained network symbol\n",
    "    arg_params: the argument parameters of the pre-trained model\n",
    "    num_classes: the number of classes for the fine-tune datasets\n",
    "    layer_name: the layer name before the last fully-connected layer\n",
    "    \"\"\"\n",
    "    all_layers = sym.get_internals()\n",
    "    net = all_layers[layer_name+'_output']\n",
    "    net = mx.symbol.FullyConnected(data=net, num_hidden=num_classes, name='fc1')\n",
    "    net = mx.symbol.SoftmaxOutput(data=net, name='softmax')\n",
    "    new_args = dict({k:arg_params[k] for k in arg_params if 'fc1' not in k})\n",
    "    return (net, new_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training the model\n",
    "\n",
    "We now define a fit function that creates an MXNet module instance that we'll bind the data and symbols to. \n",
    "\n",
    "init_params is called to randomly initialize parameters\n",
    "\n",
    "set_params is called to replace all parameters except for the last fully-connected layer with pre-trained model.\n",
    "\n",
    "#### Note: change mx.gpu to mx.cpu to run training on CPU (much slower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "head = '%(asctime)-15s %(message)s'\n",
    "logging.basicConfig(level=logging.DEBUG, format=head)\n",
    "\n",
    "def fit(symbol, arg_params, aux_params, train, val, batch_size, num_gpus=1, num_epoch=1):\n",
    "    devs = [mx.gpu(i) for i in range(num_gpus)] # replace mx.gpu by mx.cpu for CPU training\n",
    "    mod = mx.mod.Module(symbol=new_sym, context=devs)\n",
    "    mod.bind(data_shapes=train.provide_data, label_shapes=train.provide_label)\n",
    "    mod.init_params(initializer=mx.init.Xavier(rnd_type='gaussian', factor_type=\"in\", magnitude=2))\n",
    "    mod.set_params(new_args, aux_params, allow_missing=True)\n",
    "    mod.fit(train, val, \n",
    "        num_epoch=num_epoch,\n",
    "        batch_end_callback = mx.callback.Speedometer(batch_size, 10),        \n",
    "        kvstore='device',\n",
    "        optimizer='sgd',\n",
    "        optimizer_params={'learning_rate':0.009},\n",
    "        eval_metric='acc')\n",
    "    \n",
    "    return mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now that we have the helper functions setup, we can start training.\n",
    "Its recommended that you train on a GPU instance, preferably p2.* family. In this example we assume an AWS EC2 p2.xlarge, which has one NVIDIA K80 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = 2 # This is binary classification (dogs vs cat)\n",
    "batch_per_gpu = 4\n",
    "num_gpus = 1\n",
    "(new_sym, new_args) = get_fine_tune_model(sym, arg_params, num_classes)\n",
    "\n",
    "batch_size = batch_per_gpu * num_gpus\n",
    "(train, val) = get_iterators(batch_size)\n",
    "mod = fit(new_sym, new_args, aux_params, train, val, batch_size, num_gpus)\n",
    "metric = mx.metric.Accuracy()\n",
    "mod_score = mod.score(val, metric)\n",
    "print mod_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After 1 epoch we achive 97.22% training accuracy. \n",
    "\n",
    "Lets save the newly trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-01 01:33:56,263 Saved checkpoint to \"resnet-mxnet-catsvsdogs-0001.params\"\n"
     ]
    }
   ],
   "source": [
    "prefix = 'resnet-mxnet-catsvsdogs'\n",
    "epoch = 1\n",
    "mc = mod.save_checkpoint(prefix, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loading saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the model, make sure you have executed previous cells to train\n",
    "import cv2\n",
    "dshape = [('data', (1,3,224,224))]\n",
    "\n",
    "def load_model(s_fname, p_fname):\n",
    "    \"\"\"\n",
    "    Load model checkpoint from file.\n",
    "    :return: (arg_params, aux_params)\n",
    "    arg_params : dict of str to NDArray\n",
    "        Model parameter, dict of name to NDArray of net's weights.\n",
    "    aux_params : dict of str to NDArray\n",
    "        Model parameter, dict of name to NDArray of net's auxiliary states.\n",
    "    \"\"\"\n",
    "    symbol = mx.symbol.load(s_fname)\n",
    "    save_dict = mx.nd.load(p_fname)\n",
    "    arg_params = {}\n",
    "    aux_params = {}\n",
    "    for k, v in save_dict.items():\n",
    "        tp, name = k.split(':', 1)\n",
    "        if tp == 'arg':\n",
    "            arg_params[name] = v\n",
    "        if tp == 'aux':\n",
    "            aux_params[name] = v\n",
    "    return symbol, arg_params, aux_params\n",
    "\n",
    "model_symbol = \"resnet-mxnet-catsvsdogs-symbol.json\"\n",
    "model_params = \"resnet-mxnet-catsvsdogs-0002.params\"\n",
    "sym, arg_params, aux_params = load_model(model_symbol, model_params)\n",
    "mod = mx.mod.Module(symbol=sym)\n",
    "\n",
    "# bind the model and set training == False; Define the data shape\n",
    "mod.bind(for_training=False, data_shapes=dshape)\n",
    "mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generate Predictions for an arbitrary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.99993086e-01   6.96629468e-06]]\n"
     ]
    }
   ],
   "source": [
    "import urllib2\n",
    "from collections import namedtuple\n",
    "Batch = namedtuple('Batch', ['data'])\n",
    "\n",
    "def preprocess_image(img, show_img=False):\n",
    "    '''\n",
    "    convert the image to a numpy array\n",
    "    '''\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2) \n",
    "    img = img[np.newaxis, :] \n",
    "    return img\n",
    "\n",
    "url = 'https://images-na.ssl-images-amazon.com/images/G/01/img15/pet-products/small-tiles/23695_pets_vertical_store_dogs_small_tile_8._CB312176604_.jpg'\n",
    "req = urllib2.urlopen(url)\n",
    "\n",
    "image = np.asarray(bytearray(req.read()), dtype=\"uint8\")\n",
    "image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "img = preprocess_image(image)\n",
    "\n",
    "mod.forward(Batch([mx.nd.array(img)]))\n",
    "\n",
    "# predict\n",
    "prob = mod.get_outputs()[0].asnumpy()\n",
    "print prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Inspecting incorrect labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate predictions for entire validation dataset\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "path = 'data/valid/cats/' # change as needed\n",
    "files = [path + f for f in os.listdir(path)]\n",
    "incorrect_labels = []\n",
    "\n",
    "# incorrect cat labels\n",
    "for f in files:\n",
    "    img = cv2.imread(f)\n",
    "    img = preprocess_image(img)\n",
    "    mod.forward(Batch([mx.nd.array(img)]))\n",
    "    prob = mod.get_outputs()[0].asnumpy()\n",
    "    if prob.argmax() != 1: # not a cat\n",
    "        print f\n",
    "        incorrect_labels.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "# Plot helper\n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "\n",
    "#individual plot of incorrect label\n",
    "img_path = incorrect_labels[0]\n",
    "plots([cv2.imread(img_path)])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
